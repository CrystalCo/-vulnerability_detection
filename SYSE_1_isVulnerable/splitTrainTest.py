#Split Data to Train/Test (80/20)
import pickle
import os
import numpy as np
import gc

from utils.utils import init_nested_arrays

def splitTrainTest(vType, vectorPath, vectorTrainPath, vectorTestPath, randomSeed, split = 0.8):
    """
        Randomly shuffles vector pkl files to choose from. 
        Combines all the tokens (one array w/6 nested arrays), & creates 2 files with this (training/testing).
    """
    
    folders = os.listdir(vectorPath)#./data/vector
    np.random.seed(randomSeed)
    np.random.shuffle(folders)
    
    folders_train = folders[:int(len(folders)*split)+1]#8090, 8091,...
    folders_test = folders[int(len(folders)*split)+1:]
    
    #splitting method
    train_set = [] # [list of tokens (*for all training pkl files), label*, function list in each program*, filenames, vulnerability types, test case id]
    for folder_train in folders_train:
        if folder_train.endswith('DS_Store'):
            continue
        for filename in os.listdir(vectorPath+ folder_train + '/'):#./data/vector/8090
            f = open(vectorPath + folder_train + '/' + filename, 'rb')
            data = pickle.load(f)
            if train_set == []:
                train_set = init_nested_arrays(len(data))
            for n in range(len(data)):
                train_set[n] = train_set[n] + data[n]
        if train_set[0] == []:
            continue
    print("Samples in Train set: ",len(train_set[-1]))
    f_train = open(vectorTrainPath + vType + "_" + "train.pkl", 'wb')#  './data/DLvectors/train/' api_train.pkl, ALL_train.pkl
    pickle.dump(train_set, f_train, protocol=pickle.HIGHEST_PROTOCOL)
    f_train.close()
    del train_set
    gc.collect()     

   
    test_set = []
    for folder_test in folders_test:
        if folder_test.endswith('DS_Store'):
            continue
        for filename in os.listdir(vectorPath + folder_test + '/'):
            if filename.endswith('DS_Store'):
                continue
            f = open(vectorPath + folder_test + '/' + filename, 'rb')
            data = pickle.load(f)
            if test_set == []:
                test_set = init_nested_arrays(len(data))
            for n in range(len(data)):
                test_set[n] = test_set[n] + data[n]
        if test_set[0] == []:
            continue
    print("Samples in Test set: " , len(test_set[-1]))  
    f_test = open(vectorTestPath + vType + "_" + "test.pkl", 'wb')
    pickle.dump(test_set, f_test, protocol=pickle.HIGHEST_PROTOCOL)
    f_test.close()
    del test_set
    gc.collect()
    print("Finished Splitting data with seed number: " , randomSeed)
    print("Train/Test Sets saved in DLVectors folder\n")


