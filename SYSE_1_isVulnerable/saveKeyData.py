#!/usr/bin/env python
# coding: utf-8

import os
import pickle
import sys

import pandas as pd

from SYSE_2_vulnerabilityType.MLMethods import get_sard_cve_ids

def saveKeyData(traindataSet_path):
    """
        Saves key data used to fit the BGRU model.
        Uses has vulnerability (1 or 0) as labels.
        traindataSet_path := Balanced Final Train & Test Final sets in ./data/DLvectors/
    """
    for filename in os.listdir(traindataSet_path):
        if filename.endswith(".DS_Store"):
            continue
        if filename.endswith(".pkl"):
            f = open(os.path.join(traindataSet_path, filename),"rb")
            print("Save metadata from filename: " + filename)
            data = pickle.load(f)
            ids = data[5]
            mytype = data[4]
            label1 = data[1]
            print(ids[:20], "\n")
            print(label1[:20], "\n")
            print(mytype[:20], "\n") 
            metadata = "caseID, realLabel, vType \n" 
            for i in range (len(ids)):
                mystr = "{},{},{}\n".format(ids[i],label1[i],mytype[i])
                metadata = metadata + mystr
            fp = open("KeyData_" + filename + ".txt", "w", encoding="utf-8")
            fp.write(metadata)
            fp.close()
            

def saveKeyData2(traindataSet_path, groupLabels_path):
    """
        Saves key data used to fit the BGRU model.
        Uses group ids as labels.
        traindataSet_path := Balanced Final Train & Test Final sets in ./data/DLvectors/
        groupLabels_path := Set of SARD & CVE IDs that map to a group id in ./data/CVE/SARD_CVE_to_groups.csv
    """
    for filename in os.listdir(traindataSet_path):
        if filename.endswith(".DS_Store"):
            continue
        if filename.endswith(".pkl"):
            vector_path = os.path.join(traindataSet_path, filename)
            f = open(vector_path,"rb")
            print("Save metadata from filename: " + filename)
            dataset_file, labels, funcs_file, filenames_file, mytype, ids = pickle.load(f)
            f.close()

            sard_cve_ids = get_sard_cve_ids(filenames_file)
            group_ids, null_indices = get_group_ids(sard_cve_ids, groupLabels_path)
            while len(null_indices) > 0:
                # Drop rows that don't contain a group id
                i = null_indices.pop()
                ids.pop(i)
                mytype.pop(i)
                funcs_file.pop(i)
                dataset_file.pop(i)

            # SAVE AS THIS ORIGINAL PKL FILE B/C THAT'S WHAT THE KERAS MODEL IS GOING TO USE.
            f_vector = open(vector_path, 'wb')
            data = [dataset_file, group_ids, funcs_file, filenames_file, mytype, ids]
            print('Confirm all data indices contain the same amount of data: ')
            for d in data:
                print(len(d))
            pickle.dump(data, f_vector, protocol=pickle.HIGHEST_PROTOCOL)
            f_vector.close()

            print(f'Test Case IDs:\n{ids[:20]}\n')
            print(f'Vulnerability Type Labels:\n{group_ids[:20]}\n')
            print(f'Vulnerability File Type:\n{mytype[:20]}\n')
            metadata = "caseID, realLabel, vType \n" 
            for i in range (len(ids)):
                mystr = "{},{},{}\n".format(ids[i],group_ids[i],mytype[i])
                metadata = metadata + mystr
            # I DON'T SEE THIS VERSION GETTING USED ANYWHERE
            savepath = traindataSet_path + "KeyData_" + filename + ".txt"
            fp = open(savepath, "w", encoding="utf-8")
            fp.write(metadata)
            fp.close()
            
def get_group_ids(sard_cve_ids, groupLabels_path):
    i = 0
    group_ids = []
    null_indices = []
    groups_df = pd.read_csv(groupLabels_path, index_col=0)
    for sard_cve_id in sard_cve_ids:
        try:
            group_id = int(groups_df.loc[groups_df['Original ID'] == sard_cve_id]['Group ID'].item())
            group_ids.append(group_id)
        except:
            print(f'SARD {sard_cve_id} does not have a group id.')
            null_indices.append(i)
        
        i += 1
    return group_ids, null_indices
