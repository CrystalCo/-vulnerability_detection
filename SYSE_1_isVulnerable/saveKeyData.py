#!/usr/bin/env python
# coding: utf-8

import os
import pickle

import numpy as np
from utils.utils import get_category

def saveKeyData(traindataSet_path):
    """
        Saves key data used to fit the BGRU model.
        Uses binary labels.
        traindataSet_path := Balanced Final Train & Test Final sets in ./data/DLvectors/
    """
    for filename in os.listdir(traindataSet_path):
        if filename.endswith(".pkl"):
            f = open(os.path.join(traindataSet_path, filename),"rb")
            print("Save metadata from filename: " + filename)
            data = pickle.load(f)
            ids = data[-1]
            mytype = data[4]
            label1 = data[1]
            print(ids[:20], "\n")
            print(label1[:20], "\n")
            print(mytype[:20], "\n") 
            metadata = "caseID, realLabel, vType \n" 
            for i in range (len(ids)):
                mystr = "{},{},{}\n".format(ids[i],label1[i],mytype[i])
                metadata = metadata + mystr
            fp = open("KeyData_" + filename + ".txt", "w", encoding="utf-8")
            fp.write(metadata)
            fp.close()
            

def saveKeyDataMulticlass(traindataSet_path, label_encoder, output_path=None):
    """
        Saves key data used to fit the BGRU model.
        Uses group ids as labels.
        traindataSet_path := Balanced Final Train & Test Final sets in ./data/DLvectors/
    """

    for filename in os.listdir(traindataSet_path):
        if filename.endswith(".pkl"):
            vector_path = os.path.join(traindataSet_path, filename)
            f = open(vector_path,"rb")
            print("\nSave metadata from filename: " + vector_path)
            
            data = pickle.load(f)
            f.close()

            y = get_category(data[-2])
            print("Original category labels: ", np.unique(y))
            print("First 10 categories in y: ", y[:10])
            encoded_y = label_encoder.transform(y) 
            print("Encoded classes of first 10:\n", encoded_y[:10])

            print("Confirm all data indices contain the same amount of data: ")
            for d in data:
                print(len(d))
    
            data[-2] = encoded_y
            if not output_path:
                # Save as this original pkl file b/c that's what the Keras model will use.
                f_vector = open(vector_path, 'wb')
            else:
                f_vector = open(os.path.join(output_path, filename), 'wb')
            pickle.dump(data, f_vector, protocol=pickle.HIGHEST_PROTOCOL)
            f_vector.close()

