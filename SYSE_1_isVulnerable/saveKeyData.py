#!/usr/bin/env python
# coding: utf-8

import os
import pickle
import sys

def saveKeyData(traindataSet_path):
    """
        Saves key data used to fit the BGRU model.
        Uses binary labels.
        traindataSet_path := Balanced Final Train & Test Final sets in ./data/DLvectors/
    """
    for filename in os.listdir(traindataSet_path):
        if filename.endswith(".pkl"):
            f = open(os.path.join(traindataSet_path, filename),"rb")
            print("Save metadata from filename: " + filename)
            data = pickle.load(f)
            ids = data[-1]
            mytype = data[4]
            label1 = data[1]
            print(ids[:20], "\n")
            print(label1[:20], "\n")
            print(mytype[:20], "\n") 
            metadata = "caseID, realLabel, vType \n" 
            for i in range (len(ids)):
                mystr = "{},{},{}\n".format(ids[i],label1[i],mytype[i])
                metadata = metadata + mystr
            fp = open("KeyData_" + filename + ".txt", "w", encoding="utf-8")
            fp.write(metadata)
            fp.close()
            

def saveKeyDataMulticlass(traindataSet_path):
    """
        Saves key data used to fit the BGRU model.
        Uses group ids as labels.
        traindataSet_path := Balanced Final Train & Test Final sets in ./data/DLvectors/
    """
    import numpy as np
    import keras
    from keras import utils
    from keras import utils as np_utils
    from sklearn import preprocessing
    from utils.utils import get_category

    for filename in os.listdir(traindataSet_path):
        if filename.endswith(".pkl"):
            vector_path = os.path.join(traindataSet_path, filename)
            f = open(vector_path,"rb")
            print("\nSave metadata from filename: " + filename)
            # dataset_file, labels, funcs_file, filenames_file, mytype, ids = pickle.load(f)
            data = pickle.load(f)
            f.close()

            y_train = get_category(data[-2])

            # Label encoding the Y_train, Y_test, e.g. [Class A, Class B, Class C] ==> [1,2,3]
            le = preprocessing.LabelEncoder()
            le.fit(y_train)
            encoded_y_train = le.transform(y_train) 
            print("\nEncoded classes of first 10: ", encoded_y_train[:10])

            # Further encoding encoded classes ie [1,2,3] into one hot encoded form [1,0,0],[0,1,0] etc
            num_classes = np.max(encoded_y_train) + 1
            print("Num classes: ", num_classes)

            cat_y = keras.utils.np_utils.to_categorical(encoded_y_train, num_classes)  # the categorical labels for our training and testing sets; this is for Keras model to accept multiclass labels

            # Save as this original pkl file b/c that's what the Keras model will use.
            f_vector = open(vector_path, 'wb')
            data[-2] = cat_y
            print("Confirm all data indices contain the same amount of data: ")
            for d in data:
                print(len(d))
            pickle.dump(data, f_vector, protocol=pickle.HIGHEST_PROTOCOL)
            f_vector.close()

            
