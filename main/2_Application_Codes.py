#!/usr/bin/env python
# coding: utf-8

# # Application Codes
# # Execution: Kernel -> Restart & Run All
# # <font color = blue>See Project Documentation for details</font>

# ### Setting variables

# In[1]:


import os
vType = "ALL"
randomSeed = 1099
numSamples = 250 #Max Num of slice samples from each file
vectorDim = 30 #num of vector cols
slicePath = '../data/slicesSource/'
tokenPath = '../data/token/SARD/'
w2vmodelPath = '../w2vModel/model/w2vModel_ALL'
vectorPath =  '../data/vector/'
vectorTrainPath = '../data/DLvectors/train/'
vectorTestPath = '../data/DLvectors/test/'
dlInputsTrainPath = '../data/DLinputs/train/'
dlInputsTestPath  = '../data/DLinputs/test/'


# ### A. slicesToTokens.py

# In[2]:


from slicesToTokens import *
mycase_ID = tokenizeSlices(slicePath, tokenPath, numSamples)


# #### Input: 	
# - Raw Slice files.txt

# ![Screen%20Shot%202020-05-09%20at%208.25.07%20PM.png](attachment:Screen%20Shot%202020-05-09%20at%208.25.07%20PM.png)

# #### Output: 
# - .pkl files of each program, containing 5 items in array: 
# - [list of tokens, label, function list in each program, filename, vulnerability type]

# ![Screen%20Shot%202020-05-08%20at%203.48.36%20PM.png](attachment:Screen%20Shot%202020-05-08%20at%203.48.36%20PM.png)

# ### B.  isDuplicatedID.py

# In[3]:


from isDuplicatedID import *
print("The dataset has duplicated ID: ", isDuplicatedID(mycase_ID))


# ### C. tokensToVectors.py

# In[4]:


from tokensToVectors import *
myW2Vmodel = createW2VModel(w2vmodelPath, tokenPath, vectorDim)
fitW2VModel(w2vmodelPath, tokenPath, vectorPath)


# #### Input: 	
# - Tokens in index 0 in each .pkl file in './data/token/SARD'
# 
# #### Output:  
# - 1.   W2V Model created and saved in './w2vModel/w2vModel_ALL'
# - 2.	Vocabs in W2V Model saved in wordsW2Vmodel.txt
# - 3.	 index 0 is Transformed tokens to vectors saved in './data/vector/' 
#                 3.1 For 1 program, vector array has 30 columns(Vdim), row = (#of tokens)
#                 3.2 .pkl files of each program, containing 5 items in array:
#                 3.3 One token is transformed to 30 vectors as shown below
# 

# ![Screen%20Shot%202020-05-08%20at%203.51.47%20PM.png](attachment:Screen%20Shot%202020-05-08%20at%203.51.47%20PM.png)

# ### D. splitTrainTest.py

# In[5]:


from splitTrainTest import *
splitTrainTest(vType, vectorPath, vectorTrainPath, vectorTestPath,randomSeed, split = 0.8 )


# #### Input: 	
# - Vector files in './data/vector/'
# 
# #### Output:   
# - 1. ALL_Train.pkl in './data/DLvectors/train/'
# - 2. ALL_Test.pkl in './data/DLvectors/test/'
# 

# ### E. downSampling.py

# In[6]:


from downSampling import *
caseID_one,caseID_zero,downsampleNum = appendCaseIDLabel0(vectorTrainPath)
downsampling (caseID_one,caseID_zero, downsampleNum , randomSeed, vectorPath, vectorTrainPath)
#Optional used to check if the class label are balanced 
print("Class Label is balanced: " , isClassBalanced(vectorTrainPath))


# #### Input: 	
# - Train set in train.pkl
# 
# #### Output:   
# - Balanced Train set in balancedClassTrain.pkl, Saved in ./data/DLvectors/train/ 

# ### F. adjustVectorLen.py

# In[7]:


from adjustVectorLen import *
avg = meanLen(vectorTrainPath)
tranformVectorLen(vectorTrainPath, vectorTestPath, dlInputsTrainPath, dlInputsTestPath, avg, vectorDim, vType)
print("New Vector Length (rows x cols): " ,avg, " x " ,vectorDim)


# #### Input: 	
# - Balanced Train & Test sets in ./data/DLvectors/
# 
# #### Output:   
# - Balanced Train & Test sets with same length vectors in ./data/DLInputs

# ### G. saveKeyData.py

# In[8]:


from saveKeyData import *
saveKeyData(dlInputsTrainPath)
saveKeyData(dlInputsTestPath)


# #### Input: 	
# - Balanced Final Train & Test  Final sets in ./data/DLvectors/
# 
# #### Output:   
# - trainKeyData.txt, testKeyData.txt

# ### H. DLModel.py

# In[9]:


from DLModel import *
myoptimizer = 'adam' #can be changed to ‘adamax’
maxlen = avg #avg calculated from part 5.6
layers = 2
dropout = 0.2 
batchSize = 32
vectorDim = 30


# #### Input: 	
# - final train set 
# 
# #### Output:   
# - fitted BGRU model saved in './model/BRGU_ALL'

# ### Network Architechture

# ![Screen%20Shot%202020-05-08%20at%204.07.21%20PM.png](attachment:Screen%20Shot%202020-05-08%20at%204.07.21%20PM.png)

# ### Part A: BGRU

# In[10]:


#Build BGRU Model with parameters 
myKerasModel =  buildBGRU(maxlen, vectorDim, layers, dropout,myoptimizer )

#Fit BGRU Model with trained data and saved the model for later use
weightpath = './model/BRGU_ALL' + myoptimizer +str(randomSeed)
mymodel = fitModel(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed)


# ### Part B: BLSTM

# In[11]:


#Build BLSTMModel with parameters 
myKerasModel =  buildBLSTM(maxlen, vectorDim, layers, dropout,myoptimizer )

#Fit BLSTM Model with trained data and saved the model for later use
weightpath = './model/BLSTM_ALL' + myoptimizer +str(randomSeed)
mymodel = fitModel(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed)


# ### I. DLPrediction.py

# In[12]:


#all parameters are same as section 5.8
from DLModel import *
from DLPrediction import *
myoptimizer = 'adam'
maxlen = avg
layers = 2
dropout = 0.2 
batchSize = 32


# #### Input: 	
# - final test set and saved model
# 
# #### Output:   
# - output values and predicted values from Model saved to excel file: OutputSummary_adamRandomseed.xlsx

# ### Part A: BGRU

# In[13]:


modelName = 'BGRU'
weightpath = './model/BRGU_ALL' + myoptimizer +str(randomSeed)
myKerasModelADAM =  buildBGRU(maxlen,vectorDim, layers, dropout,myoptimizer )
myKerasModelADAM.load_weights(weightpath)
testID_label, output_dl_labels, mypredicted_labels, myreallabels, myvtypelabels  = predictLabel(myKerasModelADAM, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed)


# ### Part B: BLSTM

# In[14]:


modelName = 'BLSTM'
weightpath = './model/BLSTM_ALL' + myoptimizer +str(randomSeed)
myKerasModelADAM2 =  buildBLSTM(maxlen,vectorDim,layers,dropout,myoptimizer )
myKerasModelADAM2.load_weights(weightpath)
testID_label2, output_dl_labels2, mypredicted_labels2, myreallabels2, myvtypelabels  = predictLabel(myKerasModelADAM2, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed)


# ## J. ConfusionMatrix.py

# #### Input: 	
# - predicted label and real label from part I
# 
# #### Output:   
# - confusion matrix 

# In[15]:


from ConfusionMatrix import *
getConfusionMatrix(mypredicted_labels, myreallabels)#BGRU
getConfusionMatrix(mypredicted_labels2, myreallabels2)#BLSTM


# ---

# --- 

# # Output Analysis

# In[16]:


import numpy as np
import pandas as pd
import os

fileName = "OutputSummary_adamBGRU1099.xlsx"
DLdata = pd.read_excel(fileName)
DLdata.head(10)


# In[17]:


import seaborn as sns

sns.set(rc={'figure.figsize':(11.7,8.27)})
ax = sns.boxplot(x="Vtype", y='DLOutput', hue='RealLabel', data=DLdata, linewidth=1.5, palette="Set3")


# ## K. evaluateModels.py

# In[18]:


from evaluateModels import *
thresdArray = [0.40, 0.45,0.5, 0.53, 0.55, 0.58, 0.60, 0.65, 0.70, 0.8]
mydata, recall, precision, specificity, F1, Accuracy, balanceAccuracy  = combinedPredictions(thresdArray, DLdata)
mydata.to_excel("predictionWithDiffThreshold_gruadam.xlsx")  
mydata.head(10)


# ## L. plotCounts.py

# In[19]:


from plotCounts import *
colName = "Metric0.5"
mydata = mydata
plotHistogram(mydata, colName)


# In[20]:


plotBar(mydata, colName)


# In[21]:


myTable = generateMetricTabel(thresdArray, recall, precision, specificity, F1, Accuracy, balanceAccuracy)
print(myTable)


# ## Appendix A : Plot Recall VS Precision 

# In[22]:


import matplotlib.pyplot as plt
plt.scatter(precision, recall, color='blue')
plt.plot(precision, recall, color='blue')
plt.xlabel('precision')
plt.ylabel('recall')
plt.title('Recall VS Precision')
plt.legend()


# ## Appendix B : Plot F1, balancedAccuracy with Different Threshold

# In[23]:


import matplotlib.pyplot as plt
plt.scatter(thresdArray, F1, color='orange')
plt.plot(thresdArray, F1, color='orange', label="F1")
plt.scatter(thresdArray,balanceAccuracy, color='purple')
plt.plot(thresdArray, balanceAccuracy, color='purple', label="balanceAccuracy")
plt.xlabel('Threshold')
plt.ylabel('Rate')
plt.title('Metrics with Different Threshold')
plt.legend()


# ## Appendix C : Plot Accuracy, balancedAccuracy with Different Thresholds

# In[24]:


plt.scatter(thresdArray,balanceAccuracy, color='purple')
plt.plot(thresdArray, balanceAccuracy, color='purple', label="balanceAccuracy")
plt.scatter(thresdArray,Accuracy, color='pink')
plt.plot(thresdArray, Accuracy, color='pink', label="Accuracy")
plt.xlabel('Threshold')
plt.ylabel('Rate')
plt.title('Metrics with Different Threshold')
plt.legend()


# ## Appendix D : Plot Accuracy, Specificity with Different Thresholds

# In[25]:


plt.scatter(thresdArray,specificity, color='blue')
plt.plot(thresdArray, specificity, color='blue', label="specificity")
plt.scatter(thresdArray,Accuracy, color='pink')
plt.plot(thresdArray, Accuracy, color='pink', label="Accuracy")
plt.xlabel('Threshold')
plt.ylabel('Rate')
plt.title('Metrics with Different Threshold')
plt.legend()

