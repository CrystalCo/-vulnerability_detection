#!/usr/bin/env python
# coding: utf-8

# # Vulnerability Type Classification using DL
# Uses BGRU & BLSTM models to classify vulnerability type
# Categories contain non-vulnerable samples as well

# ### Setting variables
import os, sys
vType = "ALL"
randomSeed = 1099
numSamples = 420627 #Max Num of slice samples from each file
vectorDim = 30 #num of vector cols
slicePath = os.path.join('data','slicesSource')
tokenPath = os.path.join('data','token','SARD')
multiclasspath = os.path.join('data','CVE','SARD_CVE_to_groups.csv')
w2vmodelPath = os.path.join('w2vModel','model','w2vModel_ALL')
vectorPath = os.path.join('data','vector')
vectorTypePath = os.path.join('data','DLvectors')
vectorTrainPath = os.path.join(vectorTypePath,'train')
vectorTestPath = os.path.join(vectorTypePath,'test')
dlInputsTrainPath = os.path.join('data','DLinputs','train')
dlInputsTestPath  = os.path.join('data','DLinputs','test')

VUL_PATH = os.environ.get('VUL_PATH')
sys.path.insert(1, VUL_PATH)


# ### Slices To Tokens
# from SYSE_1_isVulnerable.slicesToTokens import tokenizeSlices_Multiclass
# testcase_ids, testcase_ids_per_group = tokenizeSlices_Multiclass(slicePath, tokenPath, multiclasspath, numSamples)


# ### Tokens To Vectors
# from SYSE_1_isVulnerable.tokensToVectors import createW2VModel, fitW2VModel
# myW2Vmodel = createW2VModel(w2vmodelPath, tokenPath, vectorDim)
# fitW2VModel(w2vmodelPath, tokenPath, vectorPath)


import numpy as np
import pandas as pd
from SYSE_1_isVulnerable.DLModel import buildBGRU2, buildBLSTM2, fitModel2
from SYSE_1_isVulnerable.DLPrediction import predictMulticlassLabel
from SYSE_1_isVulnerable.ConfusionMatrix import getConfusionMatrix_Multiclass
from SYSE_1_isVulnerable.evaluateModels import roc_auc_score_multiclass
from SYSE_1_isVulnerable.splitTrainTest import splitTrainTestCategorical
from SYSE_1_isVulnerable.adjustVectorLen import meanLen, tranformVectorLen
from SYSE_1_isVulnerable.saveKeyData import saveKeyDataMulticlass
from utils.utils import encode_target, getDataset


"""
#### Split into training/testing sets
splitTrainTestCategorical('balanced', vectorTypePath, vectorTrainPath, vectorTestPath, randomSeed, dropClass=None)

# ### Get number of unique classes for density value
train_data = getDataset(vectorTrainPath, getBalanced=True)
original_labels = train_data[-2]
categories = np.unique(original_labels)
mapping, labelEncoder = encode_target(categories)
density_units = categories.shape[0]

# ### Adjust Vector Length - Ensure each program (aka slice) contains the same amount of rows (i.e. tokens) in the data matrix.
avg = meanLen(vectorTrainPath)
tranformVectorLen(vectorTrainPath, vectorTestPath, dlInputsTrainPath, dlInputsTestPath, avg, vectorDim)
print(f'New Vector Length (rows x cols): {avg} x {vectorDim}\n')

### Replaces true labels with encoded labels in datafile from which our DL will train from
saveKeyDataMulticlass(dlInputsTrainPath, labelEncoder)
saveKeyDataMulticlass(dlInputsTestPath, labelEncoder)

# ### H. DLModel.py
myoptimizer = 'adam' #can be changed to ‘adamax’
maxlen = avg #avg calculated from part 5.6
layers = 2
dropout = 0.2 
batchSize = 32
vectorDim = 30
epochs = 10

                        ### Network Architecture
#################################################################################
                        ### BASE MODELS
#################################################################################
                        ### BGRU

# Create MirroredStrategy for Single-host, multi-device (GPU) synchronous training
print("\n\n===============================BASE MODELS===============================\n\n")
myKerasModel = buildBGRU2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)

# Fit BGRU Model with trained data and save the model for later use
weightpath = os.path.join('model', 'BRGU_ALL' + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed, epochs)

# ### Prediction
# #### Input: 	
# - final test set and saved model
# #### Output:   
# - output values and predicted values from Model saved to excel file: OutputSummary_adamRandomseed.xlsx
modelName = 'BGRU'
mymodel.load_weights(weightpath)
thresholds_dl_labels, mypredicted_labels, myreallabels = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
# metrics is a list containing: accuracy, micro_precision, micro_recall, micro_f1, macro_precision, macro_recall, macro_f1, weighted_precision, weighted_recall, weighted_f1
metrics = getConfusionMatrix_Multiclass(mypredicted_labels, myreallabels, saveFig=True, path='./data/plots/confusionMatrixHeatmapBGRU.png')

# ## Output Analysis
fileName = "OutputSummary_adamBGRU1099.xlsx"
DLdata = pd.read_excel(fileName)
print("\nADAM BGRU Output Summary:\n", DLdata.head(10))

# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels, mypredicted_labels)
print('\nBGRU ROC AUC Score\n', roc_auc_dict)





                        ### BLSTM

# Open a strategy scope
# with strategy.scope():
    #Build BLSTMModel with parameters 
myKerasModel =  buildBLSTM2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)

# Fit BLSTM Model with trained data and saved the model for later use
weightpath = os.path.join('model', 'BLSTM_ALL' + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed)

# ### Prediction
modelName = 'BLSTM'
mymodel.load_weights(weightpath)
thresholds_dl_labels2, mypredicted_labels2, myreallabels2  = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
metrics = getConfusionMatrix_Multiclass(mypredicted_labels2, myreallabels2, saveFig=True, path='./data/plots/confusionMatrixHeatmapBLSTM.png')

# ## Output Analysis
fileName = "OutputSummary_adamBLSTM1099.xlsx"
DLdata = pd.read_excel(fileName)
print("\nADAM BLSTM Output Summary:\n", DLdata.head(10))


# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels2, mypredicted_labels2)
print('\nROC AUC Score - BLSTM\n', roc_auc_dict)


#################################################################################
                        ### OPTIMIZATIONS
#################################################################################
                        ### WITHOUT CLASS 0
                        # Preprocessing
print("\n\n=============================== WITHOUT CLASS 0 ===============================\n\n")
#### Split new train/test sets that exclude class 0
# dropClass = 0
# splitTrainTestCategorical('balanced', vectorTypePath, vectorTrainPath, vectorTestPath, randomSeed, dropClass=dropClass)

# ### Get number of unique classes for density value
train_data = getDataset(vectorTrainPath, getBalanced=True)
original_labels = train_data[-2]
categories = np.unique(original_labels)
mapping, labelEncoder = encode_target(categories)
density_units = categories.shape[0]

# ### Adjust Vector Length
avg = meanLen(vectorTrainPath)
# tranformVectorLen(vectorTrainPath, vectorTestPath, dlInputsTrainPath, dlInputsTestPath, avg, vectorDim)
# print(f'New Vector Length (rows x cols): {avg} x {vectorDim}\n')

### Replaces true labels with encoded labels in datafile from which our DL will train from
# saveKeyDataMulticlass(dlInputsTrainPath, labelEncoder)
# saveKeyDataMulticlass(dlInputsTestPath, labelEncoder)

                        # BGRU
# Fit BGRU Model with trained data and save the model for later use
myoptimizer = 'adam' #can be changed to ‘adamax’
maxlen = avg #avg calculated from part 5.6
layers = 2
dropout = 0.2 
batchSize = 32
vectorDim = 30
epochs = 10
modelName = 'BGRU0_'

myKerasModel = buildBGRU2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)
weightpath = os.path.join('model', modelName + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed, epochs)

# ### Prediction
mymodel.load_weights(weightpath)
thresholds_dl_labels, mypredicted_labels, myreallabels = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
plotPath = "./data/plots/confusionMatrixHeatmap%s.png" % modelName
metrics = getConfusionMatrix_Multiclass(mypredicted_labels, myreallabels, saveFig=True, path=plotPath)

# ## Output Analysis
fileName = "OutputSummary_adam%s1099.xlsx" % modelName
DLdata = pd.read_excel(fileName)
print(f'\nADAM {modelName} Output Summary:\n {DLdata.head(10)}')

# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels, mypredicted_labels)
print(f'\n{modelName} ROC AUC Score\n {roc_auc_dict}')


                        ### BLSTM
# Fit BLSTM Model with trained data and saved the model for later use
modelName = 'BLSTM0_'
myKerasModel =  buildBLSTM2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)
weightpath = os.path.join('model', modelName + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed)

# ### Prediction
mymodel.load_weights(weightpath)
thresholds_dl_labels2, mypredicted_labels2, myreallabels2  = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
plotPath = "./data/plots/confusionMatrixHeatmap%s.png" % modelName
metrics = getConfusionMatrix_Multiclass(mypredicted_labels2, myreallabels2, saveFig=True, path=plotPath)

# ## Output Analysis
fileName = "OutputSummary_adam%s1099.xlsx" % modelName
DLdata = pd.read_excel(fileName)
print(f'\nADAM {modelName} Output Summary:\n {DLdata.head(10)}')

# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels2, mypredicted_labels2)
print(f'\n{modelName} ROC AUC Score\n {roc_auc_dict}')

"""



                        ### GRID SEARCH
                        # BGRU
print("\n\n=============================== GRID SEARCH - BGRU ===============================\n\n")
from sklearn.model_selection import GridSearchCV
from utils.KerasClassifier import KerasClassifier
from utils.DLCustomModels import create_bgru_model

# ### Get number of unique classes for density value
train_data = getDataset(vectorTrainPath, getBalanced=True)
x_train = train_data[0]
y_train = train_data[-2]
density_units = np.unique(y_train).shape[0]
avg = meanLen(vectorTrainPath)

param_grid = {
    'maxlen': [avg],
    'density': [density_units],
    'dropout': [0.2],
    'epochs': [10, 20], 
    'batch_size':[16, 32],
    'vector_dim':[30],
    'activation': ['sigmoid', 'softmax'],
    'optimizer': ['SGD', 'adam']
}

bgru_estimator = KerasClassifier(build_fn=create_bgru_model, verbose=1)

grid = GridSearchCV(estimator=bgru_estimator,
                    param_grid=param_grid,
                    cv=3,
                    error_score=0,
                    n_jobs=1, # change to -1 to use all processors on server
                    verbose=1)

grid.fit(x_train, y_train)

print('\nGRID SEARCH ON BGRU TRAINING DATASET COMPLETE. RESULTS:\n')
print("Best Parameters: {}\n".format(grid.best_params_))
print("Best accuracy: {}\n".format(grid.best_score_))
print("Finished.")


print("\n\n=============================== GRID SEARCH - BLSTM ===============================\n\n")
from utils.DLCustomModels import create_blstm_model
blstm_estimator = KerasClassifier(build_fn=create_blstm_model, verbose=1)
param_grid = {
    'maxlen': [avg],
    'density': [density_units],
    'dropout': [0.2],
    'epochs': [10, 20], 
    'batch_size':[16, 32],
    'vector_dim':[30],
    'activation': ['sigmoid', 'softmax'],
    'optimizer': ['SGD', 'adam']
}

grid = GridSearchCV(estimator=blstm_estimator,
                    param_grid=param_grid,
                    cv=3,
                    error_score=0,
                    n_jobs=1,
                    verbose=1)

grid.fit(x_train, y_train)

print('\nGRID SEARCH ON BGRU TRAINING DATASET COMPLETE. RESULTS:\n')
print("Best Parameters: {}\n".format(grid.best_params_))
print("Best accuracy: {}\n".format(grid.best_score_))
print("Finished.")



"""     RUN ON BEST PARAMS, WHICH REQUIRES A FEW MODIFICATIONS
# Fit BGRU Model with trained data
layers = 3
modelName = 'BGRU3_'
myKerasModel = buildBGRU2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)
weightpath = os.path.join('model', modelName + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed, epochs)

# ### Prediction
mymodel.load_weights(weightpath)
thresholds_dl_labels, mypredicted_labels, myreallabels = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
plotPath = "./data/plots/confusionMatrixHeatmap%s.png" % modelName
metrics = getConfusionMatrix_Multiclass(mypredicted_labels, myreallabels, saveFig=True, path=plotPath)

# ## Output Analysis
fileName = "OutputSummary_adam%s1099.xlsx" % modelName
DLdata = pd.read_excel(fileName)
print(f'\nADAM {modelName} Output Summary:\n {DLdata.head(10)}')

# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels, mypredicted_labels)
print(f'\n{modelName} ROC AUC Score\n {roc_auc_dict}')


                        ### BLSTM
# Fit BLSTM Model with trained data and saved the model for later use
modelName = 'BLSTM3_'
myKerasModel =  buildBLSTM2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)
weightpath = os.path.join('model', modelName + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed)

# ### Prediction
mymodel.load_weights(weightpath)
thresholds_dl_labels2, mypredicted_labels2, myreallabels2  = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
plotPath = "./data/plots/confusionMatrixHeatmap%s.png" % modelName
metrics = getConfusionMatrix_Multiclass(mypredicted_labels2, myreallabels2, saveFig=True, path=plotPath)

# ## Output Analysis
fileName = "OutputSummary_adam%s1099.xlsx" % modelName
DLdata = pd.read_excel(fileName)
print(f'\nADAM {modelName} Output Summary:\n {DLdata.head(10)}')

# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels2, mypredicted_labels2)
print(f'\n{modelName} ROC AUC Score\n {roc_auc_dict}')

"""

