#!/usr/bin/env python
# coding: utf-8

# # Vulnerability Type Classification using DL
# Uses BGRU & BLSTM models to classify vulnerability type
# Categories contain non-vulnerable samples as well

# ### Setting variables
import os, sys
vType = "ALL"
randomSeed = 1099
numSamples = 420627 #Max Num of slice samples from each file
vectorDim = 30 #num of vector cols
slicePath = os.path.join('data','slicesSource')
tokenPath = os.path.join('data','token','SARD')
multiclasspath = os.path.join('data','CVE','SARD_CVE_to_groups.csv')
w2vmodelPath = os.path.join('w2vModel','model','w2vModel_ALL')
vectorPath = os.path.join('data','vector')
vectorTypePath = os.path.join('data','DLvectors')
vectorTrainPath = os.path.join(vectorTypePath,'train')
vectorTestPath = os.path.join(vectorTypePath,'test')
dlInputsTrainPath = os.path.join('data','DLinputs','train')
dlInputsTestPath  = os.path.join('data','DLinputs','test')

VUL_PATH = os.environ.get('VUL_PATH')
sys.path.insert(1, VUL_PATH)


# ### A. slicesToTokens.py
# from SYSE_1_isVulnerable.slicesToTokens import tokenizeSlices_Multiclass
# testcase_ids, testcase_ids_per_group = tokenizeSlices_Multiclass(slicePath, tokenPath, multiclasspath, numSamples)

# # # ### B.  isDuplicatedID.py
# from SYSE_1_isVulnerable.isDuplicatedID import isDuplicatedID
# print("The dataset has duplicated ID: ", isDuplicatedID(testcase_ids))

# ### C. tokensToVectors.py
# from SYSE_1_isVulnerable.tokensToVectors import createW2VModel, fitW2VModel
# myW2Vmodel = createW2VModel(w2vmodelPath, tokenPath, vectorDim)
# fitW2VModel(w2vmodelPath, tokenPath, vectorPath)


#### Split into training/testing sets
from SYSE_1_isVulnerable.splitTrainTest import splitTrainTestCategorical
# dropClass = 697
splitTrainTestCategorical('balanced', vectorTypePath, vectorTrainPath, vectorTestPath, 0)

# ### E. Get number of unique classes for density value
import numpy as np
from utils.utils import encode_target, getDataset
all_data = getDataset(vectorTrainPath, getBalanced=True)
original_labels = all_data[-2]
categories = np.unique(original_labels)
mapping, labelEncoder = encode_target(categories)
density_units = categories.shape[0]

# ### F. adjustVectorLen.py - Ensure each program (aka slice) contains the same amount of rows (i.e. tokens) in the data matrix.
from SYSE_1_isVulnerable.adjustVectorLen import meanLen, tranformVectorLen
avg = meanLen(vectorTrainPath)
tranformVectorLen(vectorTrainPath, vectorTestPath, dlInputsTrainPath, dlInputsTestPath, avg, vectorDim)
print(f'New Vector Length (rows x cols): {avg} x {vectorDim}\n')

### G. saveKeyData.py - Used to fit BGRU model.
from SYSE_1_isVulnerable.saveKeyData import saveKeyDataMulticlass
saveKeyDataMulticlass(dlInputsTrainPath, labelEncoder)
saveKeyDataMulticlass(dlInputsTestPath, labelEncoder)


# ### H. DLModel.py
from SYSE_1_isVulnerable.DLModel import buildBGRU2, buildBLSTM2, fitModel2
myoptimizer = 'adam' #can be changed to ‘adamax’
maxlen = avg #avg calculated from part 5.6
layers = 2
dropout = 0.2 
batchSize = 32
vectorDim = 30
epochs = 10

                        ### Network Architecture
#################################################################################
                        ### Part A: BGRU
#################################################################################
# Create MirroredStrategy for Single-host, multi-device (GPU) synchronous training
# import tensorflow as tf
# from tensorflow import keras
# strategy = tf.distribute.MirroredStrategy()
# print("\nNumber of devices: {}".format(strategy.num_replicas_in_sync))


# Open a strategy scope
# with strategy.scope():
    #Build BGRU Model with parameters 
myKerasModel = buildBGRU2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)

#Fit BGRU Model with trained data and saved the model for later use
weightpath = os.path.join('model', 'BRGU_ALL' + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed, epochs)

# ### I. DLPrediction.py
# #### Input: 	
# - final test set and saved model
# #### Output:   
# - output values and predicted values from Model saved to excel file: OutputSummary_adamRandomseed.xlsx
from SYSE_1_isVulnerable.DLPrediction import predictMulticlassLabel
modelName = 'BGRU'
mymodel.load_weights(weightpath)
thresholds_dl_labels, mypredicted_labels, myreallabels = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## J. ConfusionMatrix.py
# Confusion matrix for each category.
from SYSE_1_isVulnerable.ConfusionMatrix import getConfusionMatrix_Multiclass
acc, micro_precision, micro_recall, micro_f1, macro_precision, macro_recall, macro_f1, weighted_precision, weighted_recall, weighted_f1 = getConfusionMatrix_Multiclass(mypredicted_labels, myreallabels)#BGRU

# # Output Analysis
import pandas as pd
fileName = "OutputSummary_adamBGRU1099.xlsx"
DLdata = pd.read_excel(fileName)
print("\nADAM BGRU Output Summary:\n", DLdata.head(10))

# ## K. evaluateModels.py
from SYSE_1_isVulnerable.evaluateModels import roc_auc_score_multiclass
roc_auc_dict = roc_auc_score_multiclass(myreallabels, mypredicted_labels)
print('\nROC AUC Score - BGRU\n', roc_auc_dict)

# ## L. plotCounts.py
import matplotlib.pyplot as plt
from SYSE_1_isVulnerable.plotCounts import plotBar
colName = "RealLabel"
mydata = DLdata
plt.clf()
plotBar(mydata, colName, True)
plt.clf()


# ## Appendix A : Plot Recall VS Precision 
import matplotlib.pyplot as plt
plt.scatter(weighted_precision, weighted_recall, color='blue')
plt.plot(weighted_precision, weighted_recall, color='blue')
plt.xlabel('weighted precision')
plt.ylabel('weighted recall')
plt.title('Weighted Recall VS Weighted Precision')
plt.legend()
plt.savefig('./data/plots/recallVsPrecision.png')
plt.clf()






#################################################################################
                        ### Part B: BLSTM
#################################################################################
# print("\nNumber of devices: {}".format(strategy.num_replicas_in_sync))

# Open a strategy scope
# with strategy.scope():
    #Build BLSTMModel with parameters 
myKerasModel =  buildBLSTM2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)

#Fit BLSTM Model with trained data and saved the model for later use
weightpath = os.path.join('model', 'BLSTM_ALL' + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed)

# ### I. DLPrediction.py
modelName = 'BLSTM'
mymodel.load_weights(weightpath)
thresholds_dl_labels2, mypredicted_labels2, myreallabels2  = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## J. ConfusionMatrix.py
acc, micro_precision, micro_recall, micro_f1, macro_precision, macro_recall, macro_f1, weighted_precision, weighted_recall, weighted_f1 = getConfusionMatrix_Multiclass(mypredicted_labels2, myreallabels2)#BLSTM


# # Output Analysis
fileName = "OutputSummary_adamBLSTM1099.xlsx"
DLdata = pd.read_excel(fileName)
print("\nADAM BLSTM Output Summary:\n", DLdata.head(10))


# ## K. evaluateModels.py
roc_auc_dict = roc_auc_score_multiclass(myreallabels2, mypredicted_labels2)
print('\nROC AUC Score - BLSTM\n', roc_auc_dict)


# ## L. plotCounts.py
colName = "RealLabel"
mydata = DLdata
plt.clf()
plotBar(mydata, colName, True)
plt.clf()

# ## Appendix A : Plot Recall VS Precision 
plt.scatter(weighted_precision, weighted_recall, color='blue')
plt.plot(weighted_precision, weighted_recall, color='blue')
plt.xlabel('weighted precision')
plt.ylabel('weighted recall')
plt.title('Weighted Recall VS Weighted Precision')
plt.legend()
plt.savefig('./data/plots/recallVsPrecision.png')
plt.clf()

