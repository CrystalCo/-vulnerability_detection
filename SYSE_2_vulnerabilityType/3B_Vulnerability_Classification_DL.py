#!/usr/bin/env python
# coding: utf-8

# # Vulnerability Type Classification using DL
# Uses BGRU & BLSTM models to classify vulnerability type
# Categories contain non-vulnerable samples as well

# ### Setting variables
import os, sys
vType = "ALL"
randomSeed = 1099
numSamples = 420627 #Max Num of slice samples from each file
vectorDim = 30 #num of vector cols
slicePath = os.path.join('data','slicesSource')
all_tokenPath = os.path.join('data', 'tokenFocus')  # files in here replaced the functions index with focus pointer index; generated from slicesToTokens_multiclass; ALL_tokens.pkl
tokenPath = os.path.join('data','token','SARD')
multiclasspath = os.path.join('data','CVE','SARD_CVE_to_groups.csv')
w2vmodelPath = os.path.join('w2vModel','model','w2vModel_ALL')
vectorPath = os.path.join('data','vector')
vectorTypePath = os.path.join('data','DLvectors')
vectorTrainPath = os.path.join(vectorTypePath,'train')
vectorTestPath = os.path.join(vectorTypePath,'test')
dlInputsTrainPath = os.path.join('data','DLinputs','train')
dlInputsTestPath  = os.path.join('data','DLinputs','test')

VUL_PATH = os.environ.get('VUL_PATH')
sys.path.insert(1, VUL_PATH)

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras

from SYSE_1_isVulnerable.DLModel import buildBGRU2, buildBLSTM2, fitModel2
from SYSE_1_isVulnerable.DLPrediction import predictMulticlassLabel
from SYSE_1_isVulnerable.ConfusionMatrix import getConfusionMatrix_Multiclass
from SYSE_1_isVulnerable.evaluateModels import roc_auc_score_multiclass
from SYSE_1_isVulnerable.splitTrainTest import splitTrainTestCategorical
from SYSE_1_isVulnerable.adjustVectorLen import meanLen, tranformVectorLen
from SYSE_1_isVulnerable.saveKeyData import saveKeyDataMulticlass
from utils.utils import encode_target, getDataset, save_data_to_file


# ### Slices To Tokens
# from SYSE_1_isVulnerable.slicesToTokens import tokenizeSlices_Multiclass
# testcase_ids, testcase_ids_per_group = tokenizeSlices_Multiclass(slicePath, tokenPath, multiclasspath, numSamples)


### Tokens To Vectors
# from SYSE_1_isVulnerable.tokensToVectors import createW2VModel, fitW2VModel
# myW2Vmodel = createW2VModel(w2vmodelPath, tokenPath, vectorDim)
# fitW2VModel(w2vmodelPath, tokenPath, vectorPath)

from utils.Word2VecModel import Word2VecModel
transformer = Word2VecModel(vector_size=30)
data = getDataset(dataset_path=vectorTypePath, getBalanced=True)
X = data[0]
X = transformer.fit_transform(X) # takes ~1min 30sec
data[0] = X
# Save data to a file
vectorBalancedPath=os.path.join('data','DLvectors', 'ALL_balanced')
save_data_to_file(vectorBalancedPath, 'balanced_vectors.pkl', data)

### Split into training/testing sets
splitTrainTestCategorical('balanced', vectorBalancedPath, vectorTrainPath, vectorTestPath, randomSeed=randomSeed, dropClass=None)

# ### Get number of unique classes for density value
train_data = getDataset(vectorTrainPath, getBalanced=True)
original_labels = train_data[-2]
categories = np.unique(original_labels)
mapping, labelEncoder = encode_target(categories)
density_units = categories.shape[0]

# ### Adjust Vector Length - Ensure each program (aka slice) contains the same amount of rows (i.e. tokens) in the data matrix.
avg = meanLen(vectorTrainPath)

tranformVectorLen(vectorTrainPath, vectorTestPath, dlInputsTrainPath, dlInputsTestPath, avg, vectorDim)
print(f'New Vector Length (rows x cols): {avg} x {vectorDim}\n')

### Replaces true labels with encoded labels in datafile from which our DL will train from
saveKeyDataMulticlass(dlInputsTrainPath, labelEncoder)
saveKeyDataMulticlass(dlInputsTestPath, labelEncoder)

# ### H. DLModel.py
myoptimizer = 'adam' #can be changed to ‘adamax’
maxlen = avg #avg calculated from part 5.6
layers = 2
dropout = 0.2 
batchSize = 32
vectorDim = 30
epochs = 10
"""
                        ### Network Architecture
#################################################################################
                        ### BASE MODELS
#################################################################################
                        ### BGRU

print("\n\n===============================BASE MODELS===============================\n\n")
myKerasModel = buildBGRU2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)

# Fit BGRU Model with trained data and save the model for later use
weightpath = os.path.join('model', 'BRGU_ALL' + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed, epochs)

# ### Prediction
# #### Input: 	
# - final test set and saved model
# #### Output:   
# - output values and predicted values from Model saved to excel file: OutputSummary_adamRandomseed.xlsx
modelName = 'BGRU'
mymodel.load_weights(weightpath)
thresholds_dl_labels, mypredicted_labels, myreallabels = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
# metrics is a list containing: accuracy, micro_precision, micro_recall, micro_f1, macro_precision, macro_recall, macro_f1, weighted_precision, weighted_recall, weighted_f1
metrics = getConfusionMatrix_Multiclass(mypredicted_labels, myreallabels, saveFig=True, path='./data/plots/confusionMatrixHeatmapBGRU.png')

# ## Output Analysis
fileName = "OutputSummary_adamBGRU1099.xlsx"
DLdata = pd.read_excel(fileName)
print("\nADAM BGRU Output Summary:\n", DLdata.head(10))

# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels, mypredicted_labels)
print('\nBGRU ROC AUC Score\n', roc_auc_dict)





                        ### BLSTM

# Open a strategy scope
# with strategy.scope():
    #Build BLSTMModel with parameters 
myKerasModel =  buildBLSTM2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)

# Fit BLSTM Model with trained data and saved the model for later use
weightpath = os.path.join('model', 'BLSTM_ALL' + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed)

# ### Prediction
modelName = 'BLSTM'
mymodel.load_weights(weightpath)
thresholds_dl_labels2, mypredicted_labels2, myreallabels2  = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
metrics = getConfusionMatrix_Multiclass(mypredicted_labels2, myreallabels2, saveFig=True, path='./data/plots/confusionMatrixHeatmapBLSTM.png')

# ## Output Analysis
fileName = "OutputSummary_adamBLSTM1099.xlsx"
DLdata = pd.read_excel(fileName)
print("\nADAM BLSTM Output Summary:\n", DLdata.head(10))


# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels2, mypredicted_labels2)
print('\nROC AUC Score - BLSTM\n', roc_auc_dict)


#################################################################################
                        ### OPTIMIZATIONS
#################################################################################
                        ### WITHOUT CLASS 0
                        # Preprocessing
print("\n\n=============================== WITHOUT CLASS 0 ===============================\n\n")
#### Split new train/test sets that exclude class 0
# dropClass = 0
# splitTrainTestCategorical('balanced', vectorTypePath, vectorTrainPath, vectorTestPath, randomSeed, dropClass=dropClass)

# ### Get number of unique classes for density value
train_data = getDataset(vectorTrainPath, getBalanced=True)
original_labels = train_data[-2]
categories = np.unique(original_labels)
mapping, labelEncoder = encode_target(categories)
density_units = categories.shape[0]

# ### Adjust Vector Length
avg = meanLen(vectorTrainPath)
# tranformVectorLen(vectorTrainPath, vectorTestPath, dlInputsTrainPath, dlInputsTestPath, avg, vectorDim)
# print(f'New Vector Length (rows x cols): {avg} x {vectorDim}\n')

### Replaces true labels with encoded labels in datafile from which our DL will train from
# saveKeyDataMulticlass(dlInputsTrainPath, labelEncoder)
# saveKeyDataMulticlass(dlInputsTestPath, labelEncoder)

                        # BGRU
# Fit BGRU Model with trained data and save the model for later use
myoptimizer = 'adam' #can be changed to ‘adamax’
maxlen = avg #avg calculated from part 5.6
layers = 2
dropout = 0.2 
batchSize = 32
vectorDim = 30
epochs = 10
modelName = 'BGRU0_'

myKerasModel = buildBGRU2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)
weightpath = os.path.join('model', modelName + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed, epochs)

# ### Prediction
mymodel.load_weights(weightpath)
thresholds_dl_labels, mypredicted_labels, myreallabels = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
plotPath = "./data/plots/confusionMatrixHeatmap%s.png" % modelName
metrics = getConfusionMatrix_Multiclass(mypredicted_labels, myreallabels, saveFig=True, path=plotPath)

# ## Output Analysis
fileName = "OutputSummary_adam%s1099.xlsx" % modelName
DLdata = pd.read_excel(fileName)
print(f'\nADAM {modelName} Output Summary:\n {DLdata.head(10)}')

# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels, mypredicted_labels)
print(f'\n{modelName} ROC AUC Score\n {roc_auc_dict}')


                        ### BLSTM
# Fit BLSTM Model with trained data and saved the model for later use
modelName = 'BLSTM0_'
myKerasModel =  buildBLSTM2(maxlen, vectorDim, layers, dropout, myoptimizer, density_units)
weightpath = os.path.join('model', modelName + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, maxlen, vectorDim, randomSeed)

# ### Prediction
mymodel.load_weights(weightpath)
thresholds_dl_labels2, mypredicted_labels2, myreallabels2  = predictMulticlassLabel(mymodel, dlInputsTestPath, maxlen, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
plotPath = "./data/plots/confusionMatrixHeatmap%s.png" % modelName
metrics = getConfusionMatrix_Multiclass(mypredicted_labels2, myreallabels2, saveFig=True, path=plotPath)

# ## Output Analysis
fileName = "OutputSummary_adam%s1099.xlsx" % modelName
DLdata = pd.read_excel(fileName)
print(f'\nADAM {modelName} Output Summary:\n {DLdata.head(10)}')

# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels2, mypredicted_labels2)
print(f'\n{modelName} ROC AUC Score\n {roc_auc_dict}')

"""



                                        ### RUN ON BEST PARAMS
                                            ### BGRU
print("\n\n=============================== BEST PARAMS - BGRU ===============================\n\n")
myoptimizer = 'adam' 
layers = 2
dropout = 0.2 
batchSize = 16
vectorDim = 30
epochs = 20
activation_fn = 'softmax'
modelName = 'BGRU3_'


# Create MirroredStrategy for Single-host, multi-device (GPU) synchronous training
strategy = tf.distribute.MirroredStrategy()
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))
with strategy.scope():
    myKerasModel = buildBGRU2(avg, vectorDim, layers, dropout, myoptimizer, density_units, activation_fn=activation_fn)

weightpath = os.path.join('model', modelName + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, avg, vectorDim, randomSeed, epochs)

# ### Prediction
mymodel.load_weights(weightpath)
thresholds_dl_labels, mypredicted_labels, myreallabels = predictMulticlassLabel(mymodel, dlInputsTestPath, avg, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
plotPath = "./data/plots/confusionMatrixHeatmap%s.png" % modelName
metrics = getConfusionMatrix_Multiclass(mypredicted_labels, myreallabels, saveFig=True, path=plotPath)

# ## Output Analysis
fileName = "OutputSummary_adam%s1099.xlsx" % modelName
DLdata = pd.read_excel(fileName)
print(f'\nADAM {modelName} Output Summary:\n {DLdata.head(10)}')

# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels, mypredicted_labels)
print(f'\n{modelName} ROC AUC Score\n {roc_auc_dict}')



                                            ### BLSTM
print("\n\n=============================== BEST PARAMS - BLSTM ===============================\n\n")
modelName = 'BLSTM3_'
strategy = tf.distribute.MirroredStrategy()
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))

with strategy.scope():
    myKerasModel =  buildBLSTM2(avg, vectorDim, layers, dropout, myoptimizer, density_units, activation_fn=activation_fn)

weightpath = os.path.join('model', modelName + myoptimizer +str(randomSeed))
mymodel = fitModel2(myKerasModel, weightpath, dlInputsTrainPath, batchSize, avg, vectorDim, randomSeed)

# ### Prediction
mymodel.load_weights(weightpath)
thresholds_dl_labels2, mypredicted_labels2, myreallabels2  = predictMulticlassLabel(mymodel, dlInputsTestPath, avg, vectorDim, myoptimizer, modelName, randomSeed, labelEncoder)

# ## Confusion Matrix
plotPath = "./data/plots/confusionMatrixHeatmap%s.png" % modelName
metrics = getConfusionMatrix_Multiclass(mypredicted_labels2, myreallabels2, saveFig=True, path=plotPath)

# ## Output Analysis
fileName = "OutputSummary_adam%s1099.xlsx" % modelName
DLdata = pd.read_excel(fileName)
print(f'\nADAM {modelName} Output Summary:\n {DLdata.head(10)}')

# ## ROC
roc_auc_dict = roc_auc_score_multiclass(myreallabels2, mypredicted_labels2)
print(f'\n{modelName} ROC AUC Score\n {roc_auc_dict}')



