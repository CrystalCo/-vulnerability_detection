import gc, os, pickle, shutil, time, datetime

from gensim.models.doc2vec import Doc2Vec, TaggedDocument

class DirofCorpus(object):
    def __init__(self, dirname):
        self.dirname = dirname
    
    def __iter__(self):
        d = self.dirname
        for fn in os.listdir(d): 
            if not fn.endswith('DS_Store'):
                fnn = fn
                for filename in os.listdir(os.path.join(d, fnn)):
                    if not filename.endswith('DS_Store'):
                        pklname = filename
                        with open(os.path.join(d, fnn, pklname), 'rb') as f:
                            data = pickle.load(f)
                            words = data[0][0] # array of tokens in unicode string
                            tag1 = data[4][0] # vtype (API, AE, ARR, or PTR), so we know which source file contains the test case ID
                            tag2 = fn # unique doc id, which is the test case ID of the slice
                            tags = [tag1, int(tag2)]
                            document = TaggedDocument(words, tags) # where words must be a list of unicode string tokens
                            yield document
                            del data, words, tag1, tags, document
                            gc.collect()


def createD2VModel(d2vmodelPath, tokenPath, vdim):
    print('Fitting D2V model from corpus...')
    mymodel = Doc2Vec(documents=DirofCorpus(tokenPath), alpha=0.01,  min_count=0, max_vocab_size=None, hs=0, negative=10, workers=4, vector_size=vdim)
    mymodel.save(d2vmodelPath)
    print("Model created and saved in: " + d2vmodelPath)
    words = sorted(mymodel.wv.vocab.keys())
    print("Number of words in model:", len(words))
    fp = open("wordsD2Vmodel.txt", "w", encoding="utf-8")
    for word in words:
        fp.write(word + '\n')
    fp.close()
    return mymodel


def fitD2VModel(d2vmodelPath, tokenPath, vectorPath):
    print("Vectorizing tokens with Doc2Vec model...")
    mymodel = Doc2Vec.load(d2vmodelPath)
    setDataVector(tokenPath, vectorPath, mymodel)

def setDataVector(tokenPath, vectorPath, mymodel):
    count = 0
    for corpusdir in os.listdir(tokenPath):

        if corpusdir.endswith('DS_Store'):
            continue

        if (corpusdir in os.listdir(vectorPath)) and (datetime.datetime.strptime(time.ctime(os.path.getmtime(os.path.join(vectorPath, corpusdir))), '%a %b %d %H:%M:%S %Y') < datetime.datetime(2021, 10, 18)):
            # remove any outdated vectors
            print("Removing old vector directory in vectorD2V/", corpusdir)
            shutil.rmtree(os.path.join(vectorPath, corpusdir))

        if corpusdir not in os.listdir(vectorPath):
            folder_path = os.path.join(vectorPath, corpusdir)
            os.mkdir(folder_path)
            for corpusfile in os.listdir(os.path.join(tokenPath, corpusdir)):
                if not corpusfile.endswith('pkl'):
                    continue
                corpus_path = os.path.join(tokenPath, corpusdir, corpusfile)
                f_corpus = open(corpus_path, 'rb')
                data = pickle.load(f_corpus)
                f_corpus.close()
                data[0] = [mymodel[int(corpusdir)]]
                vector_path = os.path.join(vectorPath, corpusdir, corpusfile)
                f_vector = open(vector_path, 'wb')
                pickle.dump(data, f_vector, protocol=pickle.HIGHEST_PROTOCOL)
                f_vector.close()
            count += 1
            if count % 10000 == 0:
                print(f'Done vectorizing {count} samples thus far.')

    print("D2V Completed: The vector file is in vector folder")

