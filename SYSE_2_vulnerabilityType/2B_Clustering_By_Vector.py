#!/usr/bin/env python
# coding: utf-8

# # Method 2:  Clustering by Vector
# In this method, an attempt is made to group source code slices by converting them into vectors & clustering the vectors with a similarity distance.

# ### Setting variables
import os
vType = "ALL"
randomSeed = 1099
numSamples = 22000 # Roughly max num of slice samples from each file b/c AE file only contains 22,154 total slice samples
vectorDim = 100 #num of vector cols
slicePath = './data/slicesSource/'
tokenPath = './data/token/SARD/'
d2vmodelPath = './d2vModel/model/d2vModel_ALL'
w2vmodelPath = './w2vModel/model/w2vModel_ALL'
vectorPath =  './data/vector/'
# Training & testing split, where training is balanced & testing is not
vectorTrainPath = './data/MLvectors/train/'
vectorTestPath = './data/MLvectors/test/'


# ### Updating path
# Must insert path to directory above in order to access files in main
import sys
VUL_PATH = os.environ.get('VUL_PATH')
sys.path.insert(1, VUL_PATH)


# ### A. slicesToTokens.py
# Tokens are all the words in a slice mapped to predefined tokens.  Length of tokens varies by program (aka slice).
# Each test case ID will get its own pkl file (in the SARD directory) that contains the tokenized words in index 0, its label in index 2, etc.
from SYSE_1_isVulnerable.slicesToTokens import tokenizeSlices
mycase_ID = tokenizeSlices(slicePath, tokenPath, numSamples)


# ### B. isDuplicatedID.py
from SYSE_1_isVulnerable.isDuplicatedID import isDuplicatedID
print("The dataset has duplicated ID: ", isDuplicatedID(mycase_ID))


# ### C. tokensToDocVectors.py
from tokensToDocVectors import createD2VModel, fitD2VModel
myD2Vmodel = createD2VModel(d2vmodelPath, tokenPath, vectorDim)
fitD2VModel(d2vmodelPath, tokenPath, vectorPath)


# ### D. splitTrainTest.py
from SYSE_1_isVulnerable.splitTrainTest import splitTrainTest
splitTrainTest(vType, vectorPath, vectorTrainPath, vectorTestPath,randomSeed, split = 0.8 )


# ### E. downSampling.py
from SYSE_1_isVulnerable.downSampling import appendCaseIDLabel0, downsampling, isClassBalanced
caseID_one,caseID_zero,downsampleNum = appendCaseIDLabel0(vectorTrainPath)
downsampling (caseID_one,caseID_zero, downsampleNum , randomSeed, vectorPath, vectorTrainPath)
#Optional used to check if the class label are balanced 
print("Class Label is balanced: " , isClassBalanced(vectorTrainPath))



# ### Part A. Grid Search on Clustering models with balanced dataset
from MLMethods import getDataset
dataset, labels, filenames, testcases, vtypes = getDataset(vectorTrainPath, 1, randomSeed)

import numpy as np
import pandas as pd
from sklearn.cluster import KMeans, AgglomerativeClustering
from matplotlib import pyplot as plt

from MLMethods import cv_silhouette_scorer, get_grid, plot_params

print('Hierarchical Clustering on Ward Linkage...')
n_clusters = np.arange(4,17)
affinity=['euclidean'] # Ward can only work on euclidean distance
linkage=['ward']
parameters = {'n_clusters': n_clusters, 'affinity': affinity, 'linkage': linkage}
model = AgglomerativeClustering()

grid = get_grid(model, parameters, cv_silhouette_scorer, dataset)
grid_cv_results = pd.DataFrame(grid.cv_results_)
fig=plt.figure(figsize=(5,4), dpi= 100, facecolor='w', edgecolor='k')
plot_params(n_clusters, 'K clusters', grid_cv_results['mean_train_score'], grid_cv_results['mean_test_score'], './data/Hierarchical_Clustering_Ward_Linkage_GS_Plot.png')

print('Hierarchical Clustering on Avg Linkage...')
linkage=['average']
params = {'n_clusters': n_clusters, 'affinity': affinity, 'linkage': linkage}
grid = get_grid(model, parameters, cv_silhouette_scorer, dataset)
grid_cv_results = pd.DataFrame(grid.cv_results_)
plot_params(n_clusters, 'K clusters', grid_cv_results['mean_train_score'], grid_cv_results['mean_test_score'], './data/Hierarchical_Clustering_Avg_Linkage_GS_Plot.png')

print('KMeans Clustering')
params = {'n_clusters': n_clusters, 'max_iter': [500]}
model = KMeans()
grid = get_grid(model, parameters, cv_silhouette_scorer, dataset)
plot_params(n_clusters, 'K clusters', grid.cv_results_['mean_train_score'], grid.cv_results_['mean_test_score'], './data/KMeans_GS_plot.png')

