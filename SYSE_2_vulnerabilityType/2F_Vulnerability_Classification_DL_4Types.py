"""
    The W2V data was transformed from 2D to 1D in file transform_W2V_data_for_DL_Granular.py.
    See that file for details on how data was transformed, and to see an example of the 
    DetectVulType class being used.
"""

import gc, os, sys

VUL_PATH = os.environ.get('VUL_PATH')
sys.path.insert(1, VUL_PATH)

from SYSE_2_vulnerabilityType.DetectVulType import DetectVulType
from utils.Word2VecModel import Word2VecModel
from utils.DLCustomModels import create_bgru_model, create_blstm_model
from utils.utils import getDataset


def run_all(VUL_TYPE, slicefile):
    RANDOMSEED = 1099
    CLASS_TYPE = '162_%s' % VUL_TYPE
    MODEL_TYPE = 'bgru'
    VECTOR_TRANSFORMER='w2v'
    LAYERS = 2
    DROPOUT = 0.2
    BATCHSIZE = 64
    EPOCHS = 60

    vectorRootPath = os.path.join('data','DLvectors')
    vectorsALLPath = os.path.join(vectorRootPath, f'{VUL_TYPE}_vectors')
    vectorTrainPath = os.path.join(vectorRootPath, f'train_162_{VUL_TYPE}')
    vectorTestPath = os.path.join(vectorRootPath, f'test_162_{VUL_TYPE}')
    inputsRootPath = os.path.join('data', 'DLinputs')
    dlInputsTrainPath = os.path.join(inputsRootPath, f'train_162_{VUL_TYPE}')
    dlInputsTestPath = os.path.join(inputsRootPath, f'test_162_{VUL_TYPE}')

    checkpoint_dir = './ckpt_%s_%s_%s_%s' % (VECTOR_TRANSFORMER, MODEL_TYPE, str(BATCHSIZE), CLASS_TYPE)
    model_name = '%s_%s_batch=%s_seed=%s_epochs=%s_%s' % (MODEL_TYPE.upper(), VECTOR_TRANSFORMER.upper(), BATCHSIZE, RANDOMSEED, EPOCHS, CLASS_TYPE)
    metrics_path = os.path.join(f'metrics', MODEL_TYPE)
    weights_path = os.path.join('model', model_name + 'weights')
    w2vmodelPath = os.path.join('w2vModel','model', f'w2vModel_{VUL_TYPE}')
    tokens_path = os.path.join('data', 'token', VUL_TYPE)

    dvt = DetectVulType(build_model=create_bgru_model, useGenerator=True, 
        transformer_model=Word2VecModel, transformerPath=w2vmodelPath, 
        metricsPath=metrics_path, randomSeed=RANDOMSEED, window=3, m_epochs=EPOCHS, 
        modelName=model_name, batch_size=BATCHSIZE, mask=True, dropout=DROPOUT, layers=LAYERS,
        tokensPath=tokens_path, vectorsALLPath=vectorsALLPath, vectorRootPath=vectorRootPath, 
        vectorTrainPath=vectorTrainPath, vectorTestPath=vectorTestPath, 
        inputsTrainPath=dlInputsTrainPath, inputsTestPath=dlInputsTestPath,
        checkpoint_dir=checkpoint_dir, weightpath=weights_path)


    print('Starting %s & BGRU' % VUL_TYPE)

    # Reset if need be
    print('Resetting checkpoint and weights...')
    dvt.reset_checkpoint_and_weights(dvt.weightpath)

    # scrape data only from file
    print('\nTokenizing slices...')
    all_data = [ [], [], [], [], [], [], [] ]
    all_tokensPath = os.path.join(dvt.tokensPath, 'ALL_tokens.pkl') # save to data/token/vul_type/
    dvt.tokenizeSlicesPerFile(slicefile, all_tokensPath)

    # train W2V model
    print('\nTraining W2V model...')
    dvt.init_transformer()
    # Fit transformer & transform our data
    dvt.fit_transform(dvt.transformerPath, dvt.tokensPath, dvt.vectorsALLPath, getBalanced=False)

    # Split data into training and test set
    print('\nSplitting train/test...')
    dvt.splitTrainTest(dvt.vectorsALLPath, None)

    # To flatten dataset, we must average out the dimension of the dataset which contains the tokens. AverageS out the row length per sample based on focuspointer.
    print('\nAdjusting Vector Length...')
    dvt.adjustVectorLength() # outputs to data/DLinput

    # Flatten 3D vectors to 2D
    dvt.flatten_vectors(dvt.inputsTrainPath, pcaTransformVulType=None)
    dvt.flatten_vectors(dvt.inputsTestPath, pcaTransformVulType=None)
    # Save the new vector length & avg
    data = getDataset(dvt.inputsTestPath, True)
    dvt.vector_size = len(data[0][0])
    dvt.avg = 1
    print(f'Avg: {dvt.avg}\tVector length: {dvt.vector_size}\n')
    del data
    gc.collect()

    # Build dl model & predict results
    dvt.encodeLabels()
    dvt.saveKeyData(dvt.inputsTrainPath, dvt.inputsTrainPath)
    dvt.saveKeyData(dvt.inputsTestPath, dvt.inputsTestPath)
    print('\nBuilding/fitting DL model...')
    dvt.build_and_fit()
    print('\nPredicting & Scoring...')
    dvt.predict_and_score()
    print('\n\n\n\n\n\n')


VUL_TYPE = 'AE'
slicefile = 'Arithmetic expression.txt'
run_all(VUL_TYPE, slicefile)


"""   AU   """
VUL_TYPE = 'AU'
slicefile = 'Array usage.txt'
run_all(VUL_TYPE, slicefile)


"""   API  """
VUL_TYPE = 'API'
slicefile = 'API function call.txt'
run_all(VUL_TYPE, slicefile)


"""   PTR  """
VUL_TYPE = 'PTR'
slicefile = 'Pointer usage.txt'
run_all(VUL_TYPE, slicefile)
