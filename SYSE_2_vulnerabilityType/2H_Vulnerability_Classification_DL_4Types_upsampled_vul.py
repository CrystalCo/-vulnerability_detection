"""
    Trains our models per vulnerability syntax characteristic (AE, ARR, API, or PTR)
    from our upsampled collection which contains only vulnerable samples. Since it only
    contains vulnerable samples, the full dataset size is ~213,518 which is < the original
    dataset of ~413,000.
"""

import gc, os, sys

VUL_PATH = os.environ.get('VUL_PATH')
sys.path.insert(1, VUL_PATH)

from SYSE_2_vulnerabilityType.DetectVulType import DetectVulType
from utils.Word2VecModel import Word2VecModel
from utils.DLCustomModels import create_bgru_model, create_blstm_model
from utils.utils import getDataset


def run_all(VUL_TYPE, vectorsALLdir='ALL_vectors_granular_upsampled', MODEL_TYPE='bgru', model_fn=create_bgru_model):
    RANDOMSEED = 1099
    CLASS_TYPE = '%s_upsampled' % VUL_TYPE
    VECTOR_TRANSFORMER='w2v'
    LAYERS = 2
    DROPOUT = 0.2
    BATCHSIZE = 64
    EPOCHS = 60

    inputsRootPath = os.path.join('data', 'DLinputs')
    vectorRootPath = os.path.join('data','DLvectors')
    vectorsALLPath = os.path.join(vectorRootPath, vectorsALLdir)
    # Rather than taking up memory by creating separate folders for each type, 
    # we can overwrite each one since the upsampled collection is < the fullset.
    vectorTrainPath = os.path.join(vectorRootPath, f'train_upsampled')
    vectorTestPath = os.path.join(vectorRootPath, f'test_upsampled')
    dlInputsTrainPath = os.path.join(inputsRootPath, f'train_upsampled')
    dlInputsTestPath = os.path.join(inputsRootPath, f'test_upsampled')

    checkpoint_dir = './ckpt_%s_%s_%s_%s' % (VECTOR_TRANSFORMER, MODEL_TYPE, str(BATCHSIZE), CLASS_TYPE)
    model_name = '%s_%s_batch=%s_seed=%s_epochs=%s_%s' % (MODEL_TYPE.upper(), VECTOR_TRANSFORMER.upper(), BATCHSIZE, RANDOMSEED, EPOCHS, CLASS_TYPE)
    metrics_path = os.path.join(f'metrics', MODEL_TYPE)
    weights_path = os.path.join('model', model_name + 'weights')
    w2vmodelPath = os.path.join('w2vModel','model', f'w2vModel_{VUL_TYPE}')
    tokens_path = os.path.join('data', 'token', VUL_TYPE)

    dvt = DetectVulType(build_model=model_fn, useGenerator=True, 
        transformer_model=Word2VecModel, transformerPath=w2vmodelPath, 
        metricsPath=metrics_path, randomSeed=RANDOMSEED, window=3, m_epochs=EPOCHS, 
        modelName=model_name, batch_size=BATCHSIZE, mask=True, dropout=DROPOUT, layers=LAYERS,
        tokensPath=tokens_path, vectorsALLPath=vectorsALLPath, vectorRootPath=vectorRootPath, 
        vectorTrainPath=vectorTrainPath, vectorTestPath=vectorTestPath, 
        inputsTrainPath=dlInputsTrainPath, inputsTestPath=dlInputsTestPath,
        checkpoint_dir=checkpoint_dir, weightpath=weights_path)

    print('Starting %s & %s' % (CLASS_TYPE, MODEL_TYPE))

    # Reset if need be
    print('Resetting checkpoint and weights...')
    dvt.reset_checkpoint_and_weights(dvt.weightpath)

    # train W2V model 
    #   - I dont think we need to do this since these are subsamples. I think the vectors are 
    #     created based on the words, and not their relation to other samples, but double check.
    # print('\nTraining W2V model...')
    # dvt.init_transformer()
    # # Fit transformer & transform our data
    # dvt.fit_transform(dvt.transformerPath, dvt.tokensPath, dvt.vectorsALLPath, getBalanced=False)

    # Split data into training and test set
    print('\nSplitting train/test...')
    dvt.splitTrainTestByType(VUL_TYPE, dvt.vectorsALLPath)

    # Don't adjust the row length since they're already flattened. Manually set the new vector length & avg.
    data = getDataset(dvt.vectorTestPath, True)
    dvt.vector_size = len(data[0][0])
    dvt.avg = 1
    print(f'Avg: {dvt.avg}\tVector length: {dvt.vector_size}\n')
    del data
    gc.collect()

    # Build dl model & predict results
    dvt.encodeLabels()
    dvt.saveKeyData(dvt.vectorTrainPath, dvt.inputsTrainPath)
    dvt.saveKeyData(dvt.vectorTestPath, dvt.inputsTestPath)
    print('\nBuilding/fitting DL model...')
    dvt.build_and_fit()
    print('\nPredicting & Scoring...')
    dvt.predict_and_score()
    print('\n\n\n\n\n\n')


# VUL_TYPE = 'AE'
# run_all(VUL_TYPE)

# VUL_TYPE = 'ARR'
# run_all(VUL_TYPE)

# VUL_TYPE = 'API'
# run_all(VUL_TYPE)

# VUL_TYPE = 'PTR'
# run_all(VUL_TYPE)


### BLSTM ###
VUL_TYPE = 'AE'
run_all(VUL_TYPE, vectorsALLdir='ALL_vectors_granular_upsampled', MODEL_TYPE='blstm', model_fn=create_blstm_model)

VUL_TYPE = 'ARR'
run_all(VUL_TYPE, MODEL_TYPE='blstm', model_fn=create_blstm_model)

VUL_TYPE = 'API'
run_all(VUL_TYPE, MODEL_TYPE='blstm', model_fn=create_blstm_model)

VUL_TYPE = 'PTR'
run_all(VUL_TYPE, MODEL_TYPE='blstm', model_fn=create_blstm_model)
