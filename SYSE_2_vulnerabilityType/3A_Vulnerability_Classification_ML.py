#!/usr/bin/env python
# coding: utf-8

# # Vulnerability Type Classification
# K-Nearest Neighbors will be used to classify a vulnerability type in a program.

# ### Setting variables
import os, sys
import numpy as np
import pandas as pd

vType = "ALL"
randomSeed = 1099
numSamples = 22000 #Max Num of slice samples from each file
vectorDim = 100 #num of vector cols
mergeClasses = [703, 697]
slicePath = './data/slicesSource/'
tokenPath = './data/tokenD2V/SARD/'
d2vmodelPath = './d2vModel/model/d2vModel_ALL'
vectorPath =  './data/vectorD2V/'
multiclasspath = './data/CVE/SARD_CVE_to_groups.csv'
# Training & testing split, where training is balanced & testing is not
vectorTrainPath = './data/MLvectors/train/'
vectorTestPath = './data/MLvectors/test/'

# ### Updating path
# Must insert path to directory above in order to access files in other folders
VUL_PATH = os.environ.get('VUL_PATH')
sys.path.insert(1, VUL_PATH)


# ### A. slicesToTokens.py
from SYSE_1_isVulnerable.slicesToTokens import tokenizeSlices_Multiclass
testcase_ids, testcase_ids_per_group = tokenizeSlices_Multiclass(slicePath, tokenPath, multiclasspath, numSamples, mergeClasses)

# ### B.  isDuplicatedID.py
from SYSE_1_isVulnerable.isDuplicatedID import isDuplicatedID
print("The dataset has duplicated ID: ", isDuplicatedID(testcase_ids))

# ### C. tokensToDocVectors.py
from SYSE_2_vulnerabilityType.tokensToDocVectors import createD2VModel, fitD2VModel
myD2Vmodel = createD2VModel(d2vmodelPath, tokenPath, vectorDim)
fitD2VModel(d2vmodelPath, tokenPath, vectorPath)

# ### D. splitTrainTest.py
from SYSE_1_isVulnerable.splitTrainTest import splitTrainTest
splitTrainTest(vType, vectorPath, vectorTrainPath, vectorTestPath, randomSeed, split = 0.8 )

# ### E. downSampling.py
from SYSE_1_isVulnerable.downSampling import appendCaseIDLabels, downsamplingMulticlass, isMulticlassBalanced
categoryCasesDict, downsampleNum = appendCaseIDLabels(vectorTrainPath) # data/mLvectors/ALL_*.pkl
downsamplingMulticlass(categoryCasesDict, downsampleNum, randomSeed, vectorPath, vectorTrainPath)
#Optional used to check if the class label are balanced 
print("Class Labels are balanced: %s\n" % isMulticlassBalanced(vectorTrainPath))



# ### Classification
# #### Get D2V vector datasets 
from SYSE_2_vulnerabilityType.MLMethods import getDataset, get_sard_cve_ids
data = getDataset(vectorTrainPath, True, randomSeed)
train_dataset, labels, original_labels, sard_cve_ids, testcases, vtypes = data[0], [x[0] for x in data[-2]], [x[1] for x in data[-2]], get_sard_cve_ids(data[3]), data[-1], data[4]
print('Length of training data: ', len(labels))
train_df = pd.DataFrame({'testcase': testcases, 'sard_cve_id': sard_cve_ids, 'vtype': vtypes, 'label': labels, 'og_label': original_labels})

data = getDataset(vectorTestPath, False, randomSeed)
test_dataset, labels, original_labels, sard_cve_ids, testcases, vtypes =  data[0], [x[0] for x in data[-2]], [x[1] for x in data[-2]], get_sard_cve_ids(data[3]), data[-1], data[4]

test_df = pd.DataFrame({'testcase': testcases, 'sard_cve_id': sard_cve_ids, 'vtype': vtypes, 'label': labels, 'og_label': original_labels})


# #### Set training and testing variables
# Set training data
train_data = pd.DataFrame(train_dataset)
X_train = train_data.values

# Set testing data
test_data = pd.DataFrame(test_dataset)
X_test = test_data.values



# ## K-Nearest Neighbors
from sklearn import neighbors
from SYSE_2_vulnerabilityType.MLMethods import get_grid, measure_performance

# Consider normalizing the data for better score
print('\nGrid search on KNN')
model = neighbors.KNeighborsClassifier()
scoring = 'accuracy'
parameters = {
    'n_neighbors': np.arange(1, 9, 1),
    'weights': ['uniform', 'distance'],
    'p': [1, 2], # 1 = manhattan distance, 2 = euclidean distance
}

print('Testing on original labels')
# Set target attributes
Y_train = train_df['og_label'].values
Y_test = test_df['og_label'].values

grid_cv_results = get_grid(model, parameters, scoring, X_train, Y_train)
n = grid_cv_results.best_params_['n_neighbors']
p = grid_cv_results.best_params_['p']
w = grid_cv_results.best_params_['weights']

knnclf =  neighbors.KNeighborsClassifier(n_neighbors=n, p=p, weights=w)
knnclf.fit(X_train, Y_train)

print('Measuring performance...')
print('Score on training: ', knnclf.score(X_train, Y_train))
print('Score on testing: ', knnclf.score(X_test, Y_test))
measure_performance(X_test, Y_test, knnclf, show_confusion_matrix=False)



print('\nTesting on merged labels')
# Set target attribute 
Y_train = train_df['label'].values
Y_test = test_df['label'].values

grid_cv_results = get_grid(model, parameters, scoring, X_train, Y_train)

n = grid_cv_results.best_params_['n_neighbors']
p = grid_cv_results.best_params_['p']
w = grid_cv_results.best_params_['weights']

knnclf =  neighbors.KNeighborsClassifier(n_neighbors=n, p=p, weights=w)
knnclf.fit(X_train, Y_train)

print('Measuring performance...')
print('Score on training: ', knnclf.score(X_train, Y_train))
print('Score on testing: ', knnclf.score(X_test, Y_test))

measure_performance(X_test, Y_test, knnclf)
