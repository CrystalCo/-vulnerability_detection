import os, sys
from joblib import Memory
from shutil import rmtree

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline

from SYSE_1_isVulnerable.adjustVectorLen import meanLen
from utils.utils import num_classes, encode_target
from utils.Word2VecModel import Word2VecModel
from utils.KerasClassifier import KerasClassifier
from utils.DLCustomModels import create_blstm_model

"""
    This file assumes we have already run gridSearch_W2V_BGRU.py, &
    thus have already preprocessed the slices and files. Thus, data
    should already exist in the following paths:
        './data/slicesSource/'
        './data/token/SARD/'
        './data/DLvectors/train/'
        './data/DLvectors/test/'
        './data/DLinputs/train/'
        './data/DLinputs/test/'
"""


#### Setting variables
VUL_PATH = os.environ.get('VUL_PATH') 
sys.path.insert(1, VUL_PATH)

vType = "ALL"
randomSeed = 1099
numSamples = 1000
vectorTrainPath = './data/DLvectors/train/'
vectorTestPath = './data/DLvectors/test/'
inputsTrainPath = './data/DLinputs/train/'
inputsTestPath = './data/DLinputs/test/'

print('\nHOT ENCODING CATEGORICAL LABELS...')
categories = num_classes(vectorTrainPath)
num_units = len(categories)
mapping, labelEncoder = encode_target(categories)
avg = meanLen(vectorTrainPath, vType)

# Create a temporary folder to store the transformers of the pipeline
location = 'cachedir2'
memory = Memory(location=location, verbose=2)


#### Grid Search for best parameters on W2V & BLSTM models

blstm_estimator = KerasClassifier(build_fn=create_blstm_model, verbose=3)
pipe = Pipeline([('word2vec', Word2VecModel()), ('blstm', blstm_estimator)], memory=memory, verbose=True)

param_grid = {
    'word2vec__alpha': [0.05],
    'word2vec__negative': [10, 15],
    'word2vec__epochs': [10],
    'word2vec__sample': [0.001],
    'word2vec__seed': [randomSeed],
    'word2vec__window': [2, 3, 4, 5],
    'word2vec__workers': [2],
    'word2vec__vector_size': [30],
    'blstm__maxlen': [avg],
    'blstm__density': [num_units],
    'blstm__dropout': [0.1, 0.2],
    'blstm__epochs': [10], 
    'blstm__batch_size':[32],
    'blstm__vector_dim':[30],
}

grid = GridSearchCV(estimator=pipe,
                    param_grid=param_grid,
                    cv=2,
                    error_score=0,
                    n_jobs=4, # change to -1 to use all processors on server
                    verbose=3)

print('\nGRID SEARCH ON TRAINING DATASET COMMENCING...')
from SYSE_2_vulnerabilityType.MLMethods import getDataset

data = getDataset(inputsTrainPath, False, randomSeed)
x_train = data[0]
y_train = data[-2]

grid.fit(x_train, y_train)

print('\nGRID SEARCH ON TRAINING DATASET COMPLETE. RESULTS:\n')
print("Best Parameters: {}\n".format(grid.best_params_))
print("Best accuracy: {}\n".format(grid.best_score_))
print("Finished.")

# Delete the temporary cache before exiting
memory.clear(warn=False)
rmtree(location)
