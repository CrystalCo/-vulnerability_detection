import os, sys
from joblib import Memory
from shutil import rmtree

import numpy as np
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline

#### Setting variables
vType = "ALL"
randomSeed = 1099
numSamples = 420627
slicePath = './data/slicesSource/'
tokenPath = './data/tokenD2V/SARD/'
multiclasspath = './data/CVE/SARD_CVE_to_groups.csv'
# Training & testing split, where training is balanced & testing is not
vectorTrainPath = './data/MLvectors/train/'
vectorTestPath = './data/MLvectors/test/'
# Updating path
VUL_PATH = os.environ.get('VUL_PATH') # Must insert path to directory above in order to access files in other folders
sys.path.insert(1, VUL_PATH)

"""
#### Preprocessing
print('TOKENIZING SLICES...')
# TODO: update code so that non-vulnerable samples are assigned a group ID of 0.
from SYSE_1_isVulnerable.slicesToTokens import tokenizeSlices_Multiclass
testcase_ids, testcase_ids_per_group = tokenizeSlices_Multiclass(slicePath, tokenPath, multiclasspath, numSamples)

print('\nSPLITTING INTO TRAINING/TESTING SETS...')
from SYSE_1_isVulnerable.splitTrainTest import splitTrainTest
dropClass=0
splitTrainTest(vType, tokenPath, vectorTrainPath, vectorTestPath, randomSeed, split=0.8, dropClass=dropClass)
"""

#### Grid Search for best parameters on D2V & SVC models
from utils.Doc2VecModel import Doc2VecModel
# Create a temporary folder to store the transformers of the pipeline
location = 'cachedir'
memory = Memory(location=location, verbose=1)

pipe = Pipeline([('doc2vec', Doc2VecModel()), ('svc', SVC(class_weight='balanced'))], memory=memory, verbose=True)

param_grid = {
            'doc2vec__alpha': [0.01, 0.025, 0.05],
            'doc2vec__negative': [10, 15],
            'doc2vec__window': np.arange(2, 5),
            'doc2vec__epochs': [10, 15, 20],
            'doc2vec__vector_size': [30, 50, 100, 130],
            'doc2vec__workers': [8],
            'svc__n_neighbors': np.arange(2, 5),
            'svc__C': [1, 5, 20],
            'svc__gamma':  [0.01, 0.1, 1, 5, 10],
            'decision_function_shape': ['ovo', 'ovr']
}

grid = GridSearchCV(pipe, 
            param_grid=param_grid,
            scoring='f1_weighted',
            cv=3,
            n_jobs=1,
            verbose=1)

print('\nGRID SEARCH ON TRAINING DATASET COMMENCING...')
from utils.utils import getDataset
data = getDataset(vectorTrainPath, False, randomSeed)
x_train, y_train = data[0], [d[0] for d in data[-2]]
print(f'Training dataset length: {len(x_train)}  ==  Training target length: {len(y_train)}')
fitted = grid.fit(x_train, y_train)

print('\nGRID SEARCH ON TRAINING DATASET COMPLETE. RESULTS:\n')
print("Best Parameters: {}\n".format(grid.best_params_))
print("Best accuracy: {}\n".format(grid.best_score_))
print("Finished.")

# Delete the temporary cache before exiting
memory.clear(warn=False)
rmtree(location)
