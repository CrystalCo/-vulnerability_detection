#!/usr/bin/env python
# coding: utf-8

# # Vulnerability Type Classification using ML
# The following models will be used to see which one performs best when attempting to classify a vulnerability type in a program:
# - K-Nearest Neighbors (KNN)
# - Random Forest Classifier (RFC)
# - Support Vector Classifer (SVC)

# ## Setting Variables

import gc, os, sys

import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

sys.path.insert(1, os.environ.get('VUL_PATH'))

from SYSE_1_isVulnerable.ConfusionMatrix import getConfusionMatrix_Multiclass
from SYSE_2_vulnerabilityType.DetectVulType import DetectVulType
from utils.utils import getDataset, map_pred_to_cat, save_data_to_file
from utils.MLMethods import convert_nested_lists_to_numpy_arrays, fit_transform_PCA, measure_performance, predict_and_score, test_and_get_n_for_PCA

RANDOMSEED = 1099
CLASS_TYPE = 'Granular_PCA_155'
VECTOR_TRANSFORMER='w2v'
MODEL_TYPE = 'knn'
# VECTOR_SIZE=30
vectorRootPath = os.path.join('data', 'MLvectors')
vectorsALLPath = os.path.join(vectorRootPath, 'Downsampled_vectors')
vectorTrainPath = os.path.join(vectorRootPath, 'train_155classes')
vectorTestPath = os.path.join(vectorRootPath, 'test_155classes')
inputsRootPath = os.path.join('data', 'MLinputs')
inputTrainPath = os.path.join(inputsRootPath, 'train_155classes')
inputTestPath = os.path.join(inputsRootPath, 'test_155classes')
pca_vector_train_path = os.path.join(vectorRootPath, 'PCA_train_155classes')
pca_vector_test_path = os.path.join(vectorRootPath, 'PCA_test_155classes')
pca_inputs_train_path= os.path.join(inputsRootPath, 'PCA_train_155classes')
pca_inputs_test_path= os.path.join(inputsRootPath, 'PCA_test_155classes')
metrics_path = os.path.join(f'{VECTOR_TRANSFORMER}Model', 'metrics', MODEL_TYPE)
model_name = '%s_%s_seed=%s_%s' % (MODEL_TYPE.upper(), VECTOR_TRANSFORMER.upper(), RANDOMSEED, CLASS_TYPE)


dvt = DetectVulType(build_model=KNeighborsClassifier, randomSeed=RANDOMSEED,
                    vectorsALLPath=vectorsALLPath,
                    vectorTrainPath=vectorTrainPath, vectorTestPath=vectorTestPath,
                    inputsTrainPath=inputTrainPath, inputsTestPath=inputTestPath)

# # Generated 155 classes again
# # Split Train/Test sets on all valid CWE-IDs
# dvt.splitTrainTest(dvt.vectorsALLPath, minSamples=4)
# dvt.adjustVectorLength()

# # Flatten Train
# data = getDataset(dvt.inputsTrainPath, RANDOMSEED=RANDOMSEED)
# dvt.avg = len(data[0][0])
# VECTOR_SIZE = len(data[0][0][0])
# assert len(data[0][0][0]) == VECTOR_SIZE, f'inputs data vector length {len(data[0][0][0])} != vector size {VECTOR_SIZE}'
# input_shape_1 = dvt.avg * VECTOR_SIZE
# print(f'Avg: {dvt.avg}\nVector length: {VECTOR_SIZE}')
# print(f'New vector size will be: {dvt.avg}x{VECTOR_SIZE}={str(input_shape_1)}')
# # PCA
# print('\nFlattening data for PCA transformation...')
# x_train = convert_nested_lists_to_numpy_arrays(data[0], dvt.avg, VECTOR_SIZE)
# x_train = np.reshape(x_train, (x_train.shape[0], input_shape_1))
# best_n = test_and_get_n_for_PCA(x_train)
# data[0] = fit_transform_PCA(x_train, best_n)
# save_data_to_file(pca_vector_train_path, 'DL_Final_balanced_train.pkl', data)

# # Fit PCA & Transform our test vectors
# data = getDataset(dvt.inputsTestPath, RANDOMSEED=RANDOMSEED)
# x_test = convert_nested_lists_to_numpy_arrays(data[0], dvt.avg, VECTOR_SIZE)
# x_test = np.reshape(x_test, (x_test.shape[0], input_shape_1))
# data[0] = fit_transform_PCA(x_test, best_n)
# save_data_to_file(pca_vector_test_path, 'DL_Final_balanced_test.pkl', data)


dvt.avg = 1
VECTOR_SIZE = 4438
dvt.vector_size = VECTOR_SIZE
dvt.vectorTrainPath = pca_vector_train_path
dvt.vectorTestPath = pca_vector_test_path
dvt.inputsTrainPath = pca_inputs_train_path
dvt.inputsTestPath = pca_inputs_test_path
# Hot-Encode categories
dvt.encodeLabels()
# dvt.saveKeyData(dvt.vectorTrainPath, dvt.inputsTrainPath)
# dvt.saveKeyData(dvt.vectorTestPath, dvt.inputsTestPath)


# Get train/test sets
data = getDataset(dvt.inputsTrainPath, RANDOMSEED=RANDOMSEED)
x_train = data[0]
y_train = data[-2]

data = getDataset(dvt.inputsTestPath, RANDOMSEED=RANDOMSEED)
x_test = data[0]
y_test = data[-2]
del data
gc.collect()

print(f'Length of x_train: {len(x_train)}\nLength of columns: {len(x_train[0])}')
print(f'\nLength of x_test: {len(x_test)}\nLength of columns: {len(x_test[0])}')
print(f'y_test[:3]:\n{y_test[:3]}\nNumber of labels: {len(y_test[0])}')

assert len(x_train[0]) == len(x_test[0]), f'Feature length of x_train {len(x_train[0])} should match that of x_test {len(x_test[0])}'


#### K-Nearest Neighbors
print('Commencing KNN')
knn = KNeighborsClassifier(n_neighbors=4, 
                            weights='distance', 
                            p=2,
                            n_jobs=-1).fit(x_train, y_train)
y_pred = predict_and_score(knn, 'KNN', x_test, y_test, 'test')

# Convert back to original labels
decoded_y_test = dvt.labelEncoder.inverse_transform(y_test)
decoded_y_pred = dvt.labelEncoder.inverse_transform(y_pred)
assert decoded_y_pred.shape == decoded_y_test.shape, f'Predicted array shape {decoded_y_pred.shape} should match True label array shape {decoded_y_test.shape}'

# Performance Metrics
getConfusionMatrix_Multiclass(decoded_y_pred, decoded_y_test, saveFig=True, path=metrics_path, modelName=model_name)
measure_performance(x_test, y_test, 
                    knn, show_accuracy=False, 
                    show_classification_report=True, 
                    show_confusion_matrix=False,
                    plot_cm=False)



##### Random Forest Classifier
print('\nCommencing RF')
MODEL_TYPE = 'rfc'
metrics_path = os.path.join(f'{VECTOR_TRANSFORMER}Model', 'metrics', MODEL_TYPE)
model_name = '%s_%s_seed=%s_%s' % (MODEL_TYPE.upper(), VECTOR_TRANSFORMER.upper(), RANDOMSEED, CLASS_TYPE)
rfc = RandomForestClassifier(max_features=None, n_estimators=300, criterion='entropy', 
                            max_depth=15, max_samples=0.8, min_samples_leaf=2, 
                            min_samples_split=3, n_jobs=-1, random_state=RANDOMSEED,
                            class_weight='balanced').fit(x_train, y_train)
y_pred = predict_and_score(rfc, 'Random Forest Classifier', x_test, y_test, 'test')
print(f'y_pred[:10]: ', y_pred[:10])

# Convert back to original labels
decoded_y_test = dvt.labelEncoder.inverse_transform(y_test)
decoded_y_pred = dvt.labelEncoder.inverse_transform(y_pred)
assert decoded_y_pred.shape == decoded_y_test.shape, f'Predicted array shape {decoded_y_pred.shape} should match True label array shape {decoded_y_test.shape}'

# Performance Metrics
getConfusionMatrix_Multiclass(decoded_y_pred, decoded_y_test, path=metrics_path, modelName=model_name)
measure_performance(x_test, y_test,
                    rfc, show_accuracy=False, 
                    show_classification_report=True, 
                    show_confusion_matrix=False,
                    plot_cm=False)



##### Support Vector Classifier
print('\nCommencing SVC')
MODEL_TYPE = 'svc'
metrics_path = os.path.join(f'{VECTOR_TRANSFORMER}Model', 'metrics', MODEL_TYPE)
model_name = '%s_%s_seed=%s_%s' % (MODEL_TYPE.upper(), VECTOR_TRANSFORMER.upper(), RANDOMSEED, CLASS_TYPE)
svc = SVC(class_weight='balanced', C=5, gamma=6).fit(x_train, y_train)
y_pred = predict_and_score(svc, 'Support Vector Classifier', x_test, y_test, 'test')

# Convert back to original labels
decoded_y_test = dvt.labelEncoder.inverse_transform(y_test)
decoded_y_pred = dvt.labelEncoder.inverse_transform(y_pred)
assert decoded_y_pred.shape == decoded_y_test.shape, f'Predicted array shape {decoded_y_pred.shape} should match True label array shape {decoded_y_test.shape}'

# Performance Metrics
getConfusionMatrix_Multiclass(decoded_y_pred, decoded_y_test, path=metrics_path, modelName=model_name)
measure_performance(x_test, y_test,
                    svc, show_accuracy=False, 
                    show_classification_report=True, 
                    show_confusion_matrix=False,
                    plot_cm=False)

