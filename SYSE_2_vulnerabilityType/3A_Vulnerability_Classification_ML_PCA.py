#!/usr/bin/env python
# coding: utf-8

# # Vulnerability Type Classification using ML
# The following models will be used to see which one performs best when attempting to classify a vulnerability type in a program:
# - K-Nearest Neighbors (KNN)
# - Random Forest Classifier (RFC)
# - Support Vector Classifer (SVC)

# ## Setting Variables

import gc, os, sys

import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

sys.path.insert(1, os.environ.get('VUL_PATH'))

from SYSE_1_isVulnerable.ConfusionMatrix import getConfusionMatrix_Multiclass
from SYSE_2_vulnerabilityType.DetectVulType import DetectVulType
from utils.utils import getDataset, map_pred_to_cat, save_data_to_file
from utils.MLMethods import convert_nested_lists_to_numpy_arrays, fit_transform_PCA, measure_performance, predict_and_score, test_and_get_n_for_PCA

RANDOMSEED = 1099
CLASS_TYPE = '157Granular_PCA'
VECTOR_TRANSFORMER='w2v'
MODEL_TYPE = 'knn'
VECTOR_SIZE=30
vectorRootPath = os.path.join('data', 'DLvectors')
vectorsALLPath = os.path.join(vectorRootPath, 'ALL_vectors_granular')
vectorTrainPath = os.path.join(vectorRootPath, 'train_157classes')
vectorTestPath = os.path.join(vectorRootPath, 'test_157classes')
inputsRootPath = os.path.join('data', 'DLinputs')
inputTrainPath = os.path.join(inputsRootPath, 'train_157classes')
inputTestPath = os.path.join(inputsRootPath, 'test_157classes')
pca_vector_train_path = os.path.join(vectorRootPath, 'PCA_train_157classes')
pca_vector_test_path = os.path.join(vectorRootPath, 'PCA_test_157classes')
pca_inputs_train_path= os.path.join(inputsRootPath, 'PCA_train_157classes')
pca_inputs_test_path= os.path.join(inputsRootPath, 'PCA_test_157classes')
metrics_path = os.path.join(f'{VECTOR_TRANSFORMER}Model', 'metrics', MODEL_TYPE)
model_name = '%s_%s_seed=%s_%s' % (MODEL_TYPE.upper(), VECTOR_TRANSFORMER.upper(), RANDOMSEED, CLASS_TYPE)


dvt = DetectVulType(build_model=KNeighborsClassifier, randomSeed=RANDOMSEED,
                    vectorsALLPath=vectorsALLPath, vector_size=VECTOR_SIZE,
                    vectorTrainPath=vectorTrainPath, vectorTestPath=vectorTestPath, 
                    inputsTrainPath=inputTrainPath, inputsTestPath=inputTestPath)

# Generated 157 classes again

# Split Train/Test sets on all valid CWE-IDs
dvt.splitTrainTest(dvt.vectorsALLPath)
dvt.adjustVectorLength()

# Flatten
data = getDataset(dvt.inputsTrainPath, RANDOMSEED=RANDOMSEED)
assert len(data[0][0][0]) == VECTOR_SIZE, f'inputs data vector length {len(data[0][0][0])} != vector size {VECTOR_SIZE}'
input_shape_1 = dvt.avg * VECTOR_SIZE
print(f'Avg: {dvt.avg}\nVector length: {VECTOR_SIZE}')
print(f'New vector size will be: {dvt.avg}x{VECTOR_SIZE}={str(input_shape_1)}')
# PCA
print('\nFlattening data for PCA transformation...')
x_train = convert_nested_lists_to_numpy_arrays(data[0], dvt.avg, VECTOR_SIZE)
x_train = np.reshape(x_train, (x_train.shape[0], input_shape_1))
best_n = test_and_get_n_for_PCA(x_train)
data[0] = fit_transform_PCA(x_train, best_n)
save_data_to_file(pca_vector_train_path, 'DL_Final_balanced_train.pkl', data)

# Fit PCA & Transform our test vectors
data = getDataset(dvt.inputsTestPath, RANDOMSEED=RANDOMSEED)
x_test = convert_nested_lists_to_numpy_arrays(data[0], dvt.avg, VECTOR_SIZE)
x_test = np.reshape(x_test, (x_test.shape[0], input_shape_1))
data[0] = fit_transform_PCA(x_test, best_n)
save_data_to_file(pca_vector_test_path, 'DL_Final_balanced_test.pkl', data)


dvt.avg = 1
VECTOR_SIZE = best_n
dvt.vector_size = VECTOR_SIZE
dvt.vectorTrainPath = pca_vector_train_path
dvt.vectorTestPath = pca_vector_test_path
dvt.inputsTrainPath = pca_inputs_train_path
dvt.inputsTestPath = pca_inputs_test_path
# Hot-Encode categories
dvt.encodeLabels()
dvt.saveKeyData(dvt.vectorTrainPath, dvt.inputsTrainPath)
dvt.saveKeyData(dvt.vectorTestPath, dvt.inputsTestPath)


# Get train/test sets
# We already have the flattened W2V vectors from 3D_Granular.py
data = getDataset(dvt.inputsTrainPath, RANDOMSEED=RANDOMSEED)
x_train = data[0]
print(f'Length of x_train: {len(x_train)}.\nx_train[:5]:\n{x_train[:5]}\nLength of columns: { len(x_train[0])}')
y_train = data[-2]

data = getDataset(dvt.inputsTestPath, RANDOMSEED=RANDOMSEED)
x_test = data[0]
print(f'Length of vectors in x_test: {len(x_test)}.\nx_test[:5]:\n{x_test[:5]}\nLength of columns: {len(x_test[0])}')
y_test = data[-2]
print(f'y_test[:10]: ', y_test[:10])




#### K-Nearest Neighbors
print('Commencing KNN')
knn = KNeighborsClassifier(n_neighbors=4, 
                            weights='distance', 
                            p=2,
                            n_jobs=-1).fit(x_train, y_train)
y_pred = predict_and_score(knn, 'KNN', x_test, y_test, 'test')
print(f'y_pred[:10]: ', y_pred[:10])

# Convert back to original labels
decoded_y_test = dvt.labelEncoder.inverse_transform(y_test)
decoded_y_pred = map_pred_to_cat(y_pred, dvt.labelEncoder)
assert decoded_y_pred.shape == decoded_y_test.shape, f'Predicted array shape {decoded_y_pred.shape} should match True label array shape {decoded_y_test.shape}'

# Performance Metrics
getConfusionMatrix_Multiclass(decoded_y_pred, decoded_y_test, path=metrics_path, modelName=model_name)
measure_performance(x_test, decoded_y_test, 
                    knn, show_accuracy=False, 
                    show_classification_report=True, 
                    show_confusion_matrix=False,
                    plot_cm=False)



##### Random Forest Classifier
print('\nCommencing RF')
MODEL_TYPE = 'rfc'
metrics_path = os.path.join(f'{VECTOR_TRANSFORMER}Model', 'metrics', MODEL_TYPE)
model_name = '%s_%s_seed=%s_%s' % (MODEL_TYPE.upper(), VECTOR_TRANSFORMER.upper(), RANDOMSEED, CLASS_TYPE)
rfc = RandomForestClassifier(max_features=None, n_estimators=300, criterion='entropy', 
                            max_depth=15, max_samples=0.8, min_samples_leaf=2, 
                            min_samples_split=3, n_jobs=-1, random_state=RANDOMSEED,
                            class_weight='balanced').fit(x_train, y_train)
y_pred = predict_and_score(rfc, 'Random Forest Classifier', x_test, y_test, 'test')
print(f'y_pred[:10]: ', y_pred[:10])

# Convert back to original labels
decoded_y_test = dvt.labelEncoder.inverse_transform(y_test)
decoded_y_pred = map_pred_to_cat(y_pred, dvt.labelEncoder)
assert decoded_y_pred.shape == decoded_y_test.shape, f'Predicted array shape {decoded_y_pred.shape} should match True label array shape {decoded_y_test.shape}'

# Performance Metrics
getConfusionMatrix_Multiclass(decoded_y_pred, decoded_y_test, path=metrics_path, modelName=model_name)
measure_performance(x_test, decoded_y_test, 
                    rfc, show_accuracy=False, 
                    show_classification_report=True, 
                    show_confusion_matrix=False,
                    plot_cm=False)



##### Support Vector Classifier
print('\nCommencing SVC')
MODEL_TYPE = 'svc'
metrics_path = os.path.join(f'{VECTOR_TRANSFORMER}Model', 'metrics', MODEL_TYPE)
model_name = '%s_%s_seed=%s_%s' % (MODEL_TYPE.upper(), VECTOR_TRANSFORMER.upper(), RANDOMSEED, CLASS_TYPE)
svc = SVC(class_weight='balanced', C=5, gamma=6).fit(x_train, y_train)
y_pred = predict_and_score(svc, 'Support Vector Classifier', x_test, y_test, 'test')
print(f'y_pred[:10]: ', y_pred[:10])

# Convert back to original labels
decoded_y_test = dvt.labelEncoder.inverse_transform(y_test)
decoded_y_pred = map_pred_to_cat(y_pred, dvt.labelEncoder)
assert decoded_y_pred.shape == decoded_y_test.shape, f'Predicted array shape {decoded_y_pred.shape} should match True label array shape {decoded_y_test.shape}'

# Performance Metrics
getConfusionMatrix_Multiclass(decoded_y_pred, decoded_y_test, path=metrics_path, modelName=model_name)
measure_performance(x_test, decoded_y_test,
                    svc, show_accuracy=False, 
                    show_classification_report=True, 
                    show_confusion_matrix=False,
                    plot_cm=False)

