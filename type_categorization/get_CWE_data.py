import os
import requests

"""
    Collects SARD test case IDs from the titles, gets the CWEs from the SARD’s website, & then gets the remaining attributes from the CWE website.

    PHASE 1: Collect SARD test case IDs
        1)	Extract SARD IDs from source code slice titles.
    PHASE 2: Scrape Internet for attributes
        2)	Extract CWE IDs from the SARD website.
        3)	Extract 'Name', ‘Description’, 'Abstraction', & ‘Relationship’ sections from the CWE website.
        4)  Extract CWE IDs for CVEs from multiple websites.
    PHASE 3: Format data
        5)	Use pandas to merge CVE IDs and attributes
        6)	Create dummy variables for categorical attributes
    PHASE 4: Organize data
        7)	Save the data collected in a data structure.
"""

def get_IDs(slicepath, totalSamples=None):
    """
        Extract SARD test case IDs (for CWEs) & CVE IDs from source code slice titles.
        INPUT:
            slicepath := the path where the slice source files exist. Expects a str.
            totalSamples := for testing on a small sample of slices. If None, all slices will be used. Expects int if not None.
        OUTPUT:
            Array of SARD test case IDs as strings.
            Array of CVE IDs as strings.
    """
    CVE_IDs = set()
    SARD_IDs = set()
    CVE_IDs_count = 0
    SARD_IDs_count = 0

    for filename in os.listdir(slicepath):
        SARD_IDs_by_file = set()
        CVE_IDs_by_file = set()
        if (filename.endswith(".txt") is False):
            continue
        filepath = os.path.join(slicepath, filename)
        f1 = open(filepath)
        slicelists = f1.read().split("------------------------------")
        f1.close()

        if slicelists[0] == '':
            del slicelists[0]
        if slicelists[-1] == '' or slicelists[-1] == '\n' or slicelists[-1] == '\r\n':
            del slicelists[-1]

        if (totalSamples is not None):
            # limit number of slices scanned
            slicelists = slicelists[:totalSamples]

        sard_local_count = 0   # number of SARD test case IDs found in the file
        cve_local_count = 0    # If missing SARD test case IDs, must be a CVE case
        total_slices_count = 0 
        for slicelist in slicelists:
            sentences = slicelist.split('\n')
            if sentences[0] == '\r' or sentences[0] == '':
                # Remove newlines that appear at the beginning of a title
                del sentences[0]
            if sentences == []:
                continue
            if sentences[-1] == '':
                del sentences[-1]
            if sentences[-1] == '\r':
                del sentences[-1]

            case_ID = sentences[0].split(" ")
            case_ID = case_ID[1].split("/")[0]

            if case_ID.isdigit():
                # Must be SARD ID
                SARD_IDs_by_file.add(case_ID)
                SARD_IDs.add(case_ID)
                sard_local_count += 1
            else:
                # Must be CVE
                CVE_IDs_by_file.add(case_ID)
                CVE_IDs.add(case_ID)
                cve_local_count += 1
            total_slices_count += 1
            # TODO: Is it possible for mult' SARD IDs to be in the title?
            # TODO: Is it possible for diff' CVE IDs to be in the title?
        CVE_IDs_count += cve_local_count
        SARD_IDs_count += sard_local_count

        print(f'Filename: {filename}')
        if (totalSamples):
            print(f'SARD test case IDs by file: {SARD_IDs_by_file}')
            print(f'CVE test case IDs by file: {CVE_IDs_by_file}')
        
        print(f'SARD test case IDs count by file: {sard_local_count}')
        print(f'CVE test case IDs count by file: {cve_local_count}')
        print(f'Total slices extracted: {total_slices_count} \n')
    
    print('Total SARD test case IDs found in files: %s' % SARD_IDs_count) # Should hopefully match the total slices extracted (totalSamples || 325,274)
    return CVE_IDs, SARD_IDs

def get_CWEs_from_SARD(SARD_IDs, scrapeOut, dataOut):
    """
        Extract CWE IDs from the SARD website.
        INPUT:
            SARD_IDS := Expects an array of strings with the SARD test case IDs we want to extract from the SARD site.
            scrapeOut := Expects a string path to which we can write the data from the SARD site.
            dataOut := Expects TextIOWrapper (i.e. a file we can write out the results to).
        OUTPUT:
            None. Writes results to the dataOut file.
    """
    for SARD_ID in SARD_IDs:
        url = 'https://samate.nist.gov/SARD/view_testcase.php?tID=' + SARD_ID
        # TODO: Try/Exept
        page = requests.get(url)

        with open(scrapeOut, 'w') as f:
            for line in page.text:
                try:
                    f.write(line)
                except Exception as e:
                    # ignore except error for unidentified characters in html code
                    print(f"Exception with writing to scrapeOut file: {e}")
                    pass

        with open(scrapeOut, 'r') as f:
            cwe_id = parse_SARD_page(f)
            dataOut.write(cwe_id + '\n')
            
def get_CWE_data():
    """
        Extract ‘Description’ & ‘Relationship’ sections from the CWE website.
    """
    # TODO
    return

def parse_SARD_page(data):
    flaw_delim = '<a target="_blank" href="https://cwe.mitre.org/data/definitions/'
    next_line = False

    for line in data:
        if line.find(flaw_delim) != -1:
            next_line = True
            continue
        if next_line and 'CWE' in line:
            cwe_start = line.index('CWE')
            cwe_end = line.index(': ')
            cwe = line[cwe_start:cwe_end]
            return cwe   # CWE ID    ex. CWE-476


def test__get_SARD_CVE_IDs(slicePath, totalSamples=None):
    # 1. Collect CVE & SARD test case IDs
    CVE_IDs, SARD_IDs = get_IDs(slicePath, totalSamples)
    if totalSamples:
        print('Complete set of SARD test case IDs: %s' % SARD_IDs)
        print('Complete set of CVE test case IDs: %s' % CVE_IDs)
    return CVE_IDs, SARD_IDs

def test__get_CWE_IDs(scrapeOut, dataOut, SARD_IDs):
    # 2. Scrape Internet for CWE attributes
    dataOut = open(dataOut, 'w')
    dataOut.write('CWE_ID')
    dataOut.write('\n')
    get_CWEs_from_SARD(SARD_IDs, scrapeOut, dataOut)
    dataOut.close()

 # 1. Collect CVE & SARD test case IDs
slicePath = './data/slicesSource/'
totalSamples = 15
CVE_IDs, SARD_IDs = test__get_SARD_CVE_IDs(slicePath, totalSamples)

# 2. Scrape Internet for CWE attributes
# scrapeOut = './data/CWE/scrapeOut.txt'
# dataOut = './data/CWE/CWE_Data.txt'
# test__get_CWE_IDs(scrapeOut, dataOut, SARD_IDs)

