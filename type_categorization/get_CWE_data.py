import os
import requests

"""
    Collects SARD test case IDs from the titles, gets the CWEs from the SARD’s website, & then gets the remaining attributes from the CWE website.

    PHASE 1: Collect test case IDs
        1)	Extract SARD IDs & CVE IDs from source code slice titles.
    PHASE 2: Scrape Internet for attributes
        2)	Extract CWE IDs from the SARD website.
        3)	Extract 'Name', ‘Description’, 'Abstraction', & ‘Relationship’ sections from the CWE website.
        4)  Extract CWE IDs for CVEs from multiple websites.
    PHASE 3: Format data
        5)	Use pandas to merge CVE IDs and attributes
        6)	Create dummy variables for categorical attributes
    PHASE 4: Organize data
        7)	Save the data collected in a data structure.
"""

def get_IDs(slicepath, totalSamples=None):
    """
        Extract SARD test case IDs (for CWEs) & CVE IDs from source code slice titles.
        INPUT:
            slicepath := the path where the slice source files exist. Expects a str.
            totalSamples := for testing on a small sample of slices. If None, all slices will be used. Expects int if not None.
        OUTPUT:
            Array of SARD test case IDs as strings.
            Array of CVE IDs as strings.
    """
    CVE_IDs = set()
    SARD_IDs = set()
    CVE_IDs_count = 0
    SARD_IDs_count = 0

    for filename in os.listdir(slicepath):
        SARD_IDs_by_file = set()
        CVE_IDs_by_file = set()
        if (filename.endswith(".txt") is False):
            continue
        filepath = os.path.join(slicepath, filename)
        f1 = open(filepath)
        slicelists = f1.read().split("------------------------------")
        f1.close()

        if slicelists[0] == '':
            del slicelists[0]
        if slicelists[-1] == '' or slicelists[-1] == '\n' or slicelists[-1] == '\r\n':
            del slicelists[-1]

        if (totalSamples is not None):
            # limit number of slices scanned
            slicelists = slicelists[:totalSamples]

        sard_local_count = 0   # number of SARD test case IDs found in the file
        cve_local_count = 0    # If missing SARD test case IDs, must be a CVE case
        total_slices_count = 0 
        for slicelist in slicelists:
            sentences = slicelist.split('\n')
            if sentences[0] == '\r' or sentences[0] == '':
                # Remove newlines that appear at the beginning of a title
                del sentences[0]
            if sentences == []:
                continue
            if sentences[-1] == '':
                del sentences[-1]
            if sentences[-1] == '\r':
                del sentences[-1]

            case_ID = sentences[0].split(" ")
            case_ID = case_ID[1].split("/")[0]

            if case_ID.isdigit():
                # Must be SARD ID
                SARD_IDs_by_file.add(case_ID)
                SARD_IDs.add(case_ID)
                sard_local_count += 1
            else:
                # Must be CVE
                CVE_IDs_by_file.add(case_ID)
                CVE_IDs.add(case_ID)
                cve_local_count += 1
            total_slices_count += 1
            # TODO: Is it possible for mult' SARD IDs to be in the title?
            # TODO: Is it possible for diff' CVE IDs to be in the title?
        CVE_IDs_count += cve_local_count
        SARD_IDs_count += sard_local_count

        print(f'Filename: {filename}')
        if (totalSamples):
            print(f'SARD test case IDs by file: {SARD_IDs_by_file}')
            print(f'CVE test case IDs by file: {CVE_IDs_by_file}')
        
        print(f'SARD test case IDs count by file: {sard_local_count}')
        print(f'CVE test case IDs count by file: {cve_local_count}')
        print(f'Total slices extracted: {total_slices_count} \n')
    
    print('Total SARD test case IDs found in files: %s' % SARD_IDs_count) # Should hopefully match the total slices extracted (totalSamples || 325,274)
    return CVE_IDs, SARD_IDs

def get_CWEs_from_SARD(SARD_IDs, scrapeOut, dataOut):
    """
        Extract CWE IDs from the SARD website.
        INPUT:
            SARD_IDS := Expects an array of strings with the SARD test case IDs we want to extract from the SARD site.
            scrapeOut := Expects a string path to which we can write the data from the SARD site.
            dataOut := Expects TextIOWrapper (i.e. a file we can write out the results to).
        OUTPUT:
            Writes results to the dataOut file.
    """
    for SARD_ID in SARD_IDs:
        url = 'https://samate.nist.gov/SARD/view_testcase.php?tID=' + SARD_ID
        # TODO: Try/Exept
        page = requests.get(url)

        with open(scrapeOut, 'w') as f:
            for line in page.text:
                try:
                    f.write(line)
                except Exception as e:
                    # ignore except error for unidentified characters in html code
                    print(f"Exception with writing to scrapeOut file: {e}")
                    pass

        with open(scrapeOut, 'r') as f:
            cwe_id = parse_SARD_page(f)
            dataOut.write(cwe_id + '\n')
            
def get_CWE_data(CWE_IDs, scrapeOut, dataOut):
    """
        Extract 'Name', ‘Description’, 'Abstraction', & ‘Relationship’ sections from the CWE website.
        INPUT:
            CWE_IDs := Expects an array of strings with the CWE ID we want from the CWE site.
            scrapeOut := Expects a string path to which we can write the data from the CWE site.
            dataOut := Expects TextIOWrapper (i.e. a file we can write out the results to).
        OUTPUT:
            Writes results to the dataOut file.
    """
    for CWE_ID in CWE_IDs:
        cid = CWE_ID.split('-')[1]
        cid = int(cid) # Strips 0s from the beginning of the CWE id
        cid = str(cid)
        url = 'https://cwe.mitre.org/data/definitions/%s.html' % cid
        page = requests.get(url)

        with open(scrapeOut, 'w') as f:
            for line in page.text:
                try:
                    f.write(line)
                except Exception as e:
                    # ignore except error for unidentified characters in html code
                    print(f"Exception with writing to scrapeOut file: {e}")
                    pass
        
        with open(scrapeOut, 'r') as f:
            # [name, abstraction, description, relationships] 
            CWE_Data = parse_CWE_page(f, cid)

            if CWE_Data == ["", "", "", []]:
                print('No data for CWE ID: ', CWE_ID)
                continue
            
            # ['CWE_ID', 'Name', 'Abstraction', 'Description', 'Relationships', 'URL']
            out = '\t'.join([cid, CWE_Data[0], CWE_Data[1], CWE_Data[2], ','.join(CWE_Data[3]), url])
            dataOut.write(out + '\n')
    
def parse_SARD_page(dataFile):
    flaw_delim = '<a target="_blank" href="https://cwe.mitre.org/data/definitions/'
    next_line = False

    for line in dataFile:
        if line.find(flaw_delim) != -1:
            next_line = True
            continue
        if next_line and 'CWE' in line:
            cwe_start = line.index('CWE')
            cwe_end = line.index(': ')
            cwe = line[cwe_start:cwe_end]
            return cwe   # CWE ID    ex. CWE-476

def parse_CWE_page(dataFile, CWE_ID):
    name_delim = 'text-bottom">CWE-%s: ' % CWE_ID
    abstraction_delim = 'Abstraction: <span style="font-weight:normal">'
    # description_delim = '<div name="oc_121_Description" id="oc_121_Description" class="expandblock"><div class="detail"><div class="indent">'
    description_delim = '<div name="oc_%s_Description" id="oc_%s_Description" class="expandblock"><div class="detail"><div class="indent">' % (CWE_ID, CWE_ID)
    relationships_delim = 'language, and resource.</span></span></td><td valign="top">'

    # name, abstraction, description, relationship ids
    CWE_Data = ["", "", "", []]

    for line in dataFile:
        if name_delim in line:
            name_start = line.split(name_delim)[1]
            name = name_start.split('</h2')[0]
            CWE_Data[0] = name

            abstraction_start = line.split(abstraction_delim)[1]
            abstraction = abstraction_start.split('</span')[0]
            CWE_Data[1] = abstraction

        if description_delim in line:
            desc_start = line.split(description_delim)[1]
            description = desc_start.split('</div')[0]
            CWE_Data[2] = description

        if relationships_delim in line:
            id_start = line.split(relationships_delim)[1]
            relationship_id = id_start.split('</td')[0]
            CWE_Data[3].append(relationship_id)

    return CWE_Data

def get_CWE_IDs(dataFile):
    data = open(dataFile, 'r')
    CWE_IDs = [] 
    for line in data:
        CWE_IDs.append(line.rstrip('\n'))
    data.close()
    # Remove header
    CWE_IDs.pop(0)
    return CWE_IDs

def test__get_SARD_CVE_IDs(slicePath, totalSamples=None):
    # 1. Collect CVE & SARD test case IDs
    CVE_IDs, SARD_IDs = get_IDs(slicePath, totalSamples)
    if totalSamples:
        print('Complete set of SARD test case IDs: %s' % SARD_IDs)
        print('Complete set of CVE test case IDs: %s' % CVE_IDs)
    return CVE_IDs, SARD_IDs

def test__get_CWE_IDs_from_SARD(scrapeOut, dataOut, SARD_IDs):
    # 2. Scrape Internet for CWE ids from SARD website
    dataOut = open(dataOut, 'w')
    dataOut.write('CWE_ID')
    dataOut.write('\n')
    get_CWEs_from_SARD(SARD_IDs, scrapeOut, dataOut)
    dataOut.close()

def test__get_CWE_Data(scrapeOut, dataOut, IDs):
    # 2. Extract 'Name', ‘Description’, 'Abstraction', & ‘Relationship’ sections from the CWE website.
    dataOut = open(dataOut, 'w')
    dataOut.write('\t'.join(['CWE_ID', 'Name', 'Abstraction', 'Description', 'Relationships', 'URL']))
    dataOut.write('\n')
    get_CWE_data(IDs, scrapeOut, dataOut)
    dataOut.close()

# Phase 1. Collect CVE & SARD test case IDs
# slicePath = './data/slicesSource/'
# totalSamples = 15         # for testing
# CVE_IDs, SARD_IDs = test__get_SARD_CVE_IDs(slicePath, totalSamples)

# Phase 2. Scrape Internet for CWE attributes
# 2)	Extract CWE IDs from the SARD website.
scrapeOut = './data/CWE/scrapeOut.txt'
dataOut = './data/CWE/CWE_IDs.txt'
# test__get_CWE_IDs_from_SARD(scrapeOut, dataOut, SARD_IDs)

# 3)	Extract 'Name', ‘Description’, 'Abstraction', & ‘Relationship’ sections from the CWE website.
CWE_IDs = get_CWE_IDs(dataOut)
# sample_CWE_IDs = CWE_IDs[:totalSamples]   # for testing
dataOut = './data/CWE/CWE_Data.txt'

test__get_CWE_Data(scrapeOut, dataOut, CWE_IDs)



# 4)  Extract CWE IDs for CVEs from multiple websites.
