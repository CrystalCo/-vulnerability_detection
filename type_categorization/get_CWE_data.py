import os
import requests

"""
    Collects SARD test case IDs from the titles, gets the CWEs from the SARD’s website, & then gets the remaining attributes from the CWE website.

    PHASE 1: Collect SARD test case IDs
        1)	Extract SARD IDs from source code slice titles.
    PHASE 2: Scrape Internet for attributes
        2)	Extract CWE IDs from the SARD website.
        3)	Extract ‘Description’ & ‘Relationship’ sections from the CWE website.
    PHASE 3: Format data
        4)	Save the data collected in a data structure 
        5)	Create dummy variables for categorical attributes
"""
def get_SARD_IDs(slicepath, totalSamples=None):
    """
        Extract SARD test case IDs from source code slice titles.
        INPUT:
            slicepath := the path where the slice source files exist. Expects a str.
            totalSamples := for testing on a small sample of slices. If None, all slices will be used. Expects int if not None.
        OUTPUT:
            Array of SARD test case IDs as strings.
    """
    SARD_IDs = set()
    SARD_IDs_count = 0

    for filename in os.listdir(slicepath):
        SARD_IDs_by_file = set()
        if (filename.endswith(".txt") is False):
            continue
        filepath = os.path.join(slicepath, filename)
        f1 = open(filepath)
        slicelists = f1.read().split("------------------------------")
        f1.close()

        if slicelists[0] == '':
            del slicelists[0]
        if slicelists[-1] == '' or slicelists[-1] == '\n' or slicelists[-1] == '\r\n':
            del slicelists[-1]

        if (totalSamples is not None):
            # limit number of slices scanned
            slicelists = slicelists[:totalSamples]

        total_local_count = 0   # number of SARD test case IDs found in the file
        missing_id_count = 0    # Checks if missing any SARD test case IDs
        for slicelist in slicelists:
            sentences = slicelist.split('\n')
            if sentences[0] == '\r' or sentences[0] == '':
                # Remove newlines that appear at the beginning of a title
                del sentences[0]
            if sentences == []:
                continue
            if sentences[-1] == '':
                del sentences[-1]
            if sentences[-1] == '\r':
                del sentences[-1]

            SARD_ID = sentences[0].split(" ")[1].split("/")[0]
            # for example, title = 56327 151098/ffmpeg.c memset 344

            # Double-check that all SARD IDs are ints
            if (not int(SARD_ID)):
                missing_id_count += 1
                print(f"Missing ID: {sentences[0]}")
                continue
            # TO DO: Is it possible for mult' SARD IDs to be in the title?

            SARD_IDs_by_file.add(SARD_ID)
            SARD_IDs.add(SARD_ID)
            SARD_IDs_count += 1
            total_local_count += 1

        print(f'Filename: {filename}')
        print(f'SARD test case IDs by file: {SARD_IDs_by_file}')
        if missing_id_count:
            print(f'Missing ID Count: {missing_id_count}')
        print(f'Total slices extracted: {total_local_count} \n')
    
    print('Total SARD test case IDs found in files: %s' % SARD_IDs_count) # Should hopefully match the total slices extracted (totalSamples || 325,274)
    return SARD_IDs

def get_CWEs_from_SARD(SARD_IDs, scrapeOut, dataOut):
    """
        Extract CWE IDs from the SARD website.
        INPUT:
            SARD_IDS := Expects an array of strings with the SARD test case IDs we want to extract from the SARD site.
            scrapeOut := Expects a string path to which we can write the data from the SARD site.
            dataOut := Expects TextIOWrapper (i.e. a file we can write out the results to).
        OUTPUT:
            None. Writes results to the dataOut file.
    """
    for SARD_ID in SARD_IDs:
        url = 'https://samate.nist.gov/SARD/view_testcase.php?tID=' + SARD_ID
        page = requests.get(url)

        with open(scrapeOut, 'w') as f:
            for line in page.text:
                try:
                    f.write(line)
                except Exception as e:
                    # ignore except error for unidentified characters in html code
                    print(f"Exception with writing to scrapeOut file: {e}")
                    pass

        with open(scrapeOut, 'r') as f:
            cwe_id = parse_SARD_page(f)
            dataOut.write(cwe_id + '\n')
            

def parse_SARD_page(data):
    flaw_delim = '<a target="_blank" href="https://cwe.mitre.org/data/definitions/'
    next_line = False

    for line in data:
        if line.find(flaw_delim) != -1:
            next_line = True
            continue
        if next_line and 'CWE' in line:
            cwe_start = line.index('CWE')
            cwe_end = line.index(': ')
            cwe = line[cwe_start:cwe_end]
            return cwe   # CWE ID    ex. CWE-476


def test__get_CWE_Data(slicePath, totalSamples=None):
    # 1. Collect SARD test case IDs
    SARD_IDs = get_SARD_IDs(slicePath, totalSamples)
    if totalSamples:
        print('Complete set of SARD test case IDs: %s' % SARD_IDs)
    # 2. Scrape Internet for attributes
    scrapeOut = './data/CWE/scrapeOut.txt'
    dataOut = open('./data/CWE/CWE_Data.txt', 'w')
    dataOut.write('CWE_ID')
    dataOut.write('\n')
    get_CWEs_from_SARD(SARD_IDs, scrapeOut, dataOut)
    dataOut.close()

slicePath = './data/slicesSource/'
totalSamples = 1
test__get_CWE_Data(slicePath, totalSamples)
