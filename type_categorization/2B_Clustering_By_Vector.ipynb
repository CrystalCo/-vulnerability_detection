{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3b239b",
   "metadata": {},
   "source": [
    "# Method 2:  Clustering by Vector\n",
    "The goal remains to group weaknesses/vulnerabilities by similarity.  In method 1, group definitions were extracted from the [CWE website's](https://cwe.mitre.org/index.html), which contained a predefined hierarchical graph for CWE IDs.  Then, the tree was traversed to return a subset that contained the CWE IDs found in the original dataset (from the source code slices) and their overarching primary group listing.  This produced 15 groups that varied in size from 52 to 274,281.  For example, the source code contained 52 slices of code containing a potential CWE-398 weakness.  ['Code Quality' (CWE-398)](https://cwe.mitre.org/data/definitions/700.html) is a top-level category according to the CWE website.  No other CWE-IDs were obtained from our slices that fell under the CWE-398's branch, and therefore Group #14 is named 'Code Quality' and has a size of 52.  On the other hand, 'Improper Control of a Resource Through its Lifetime' (CWE-664) contained a majority of CWE-IDs (75 out of the 166 unique CWE-IDs in the source code slices) and sample counts, totaling 274,281 samples, which is approximately 66.3% of all the samples/groups.\n",
    "\n",
    "In this method, an attempt is made to group source code slices by converting them into vectors & clustering the vectors with a similarity distance.\n",
    "\n",
    "Out of the 420,627 slices, 1,369 slices contained deprecated or obsolete CWE-IDs and 5,286 slices obtained by CVEs did not have a CWE-ID associated with them.  Thus, a maximum of 413,972 slices should be used in the training model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6084a33c",
   "metadata": {},
   "source": [
    "### Setting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03d3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "vType = \"ALL\"\n",
    "randomSeed = 1099\n",
    "numSamples = 250 #Max Num of slice samples from each file\n",
    "vectorDim = 30 #num of vector cols\n",
    "slicePath = '../data/slicesSource/'\n",
    "tokenPath = '../data/token/SARD/'\n",
    "w2vmodelPath = '../w2vModel/model/w2vModel_ALL'\n",
    "vectorPath =  '../data/vector/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d57aa",
   "metadata": {},
   "source": [
    "### A. slicesToTokens.py\n",
    "Which slices we obtain for the tokens is important.   In order to avoid choosing slices that contained an obsolete, deprecated, or no CWE-ID, we either need to \n",
    "1. create new source code files containing a subset of slices with valid CWE-IDs associated with them (ones that aren't obsolete or missing); or \n",
    "2. create a modified version of the slicesToTokens.py file that will return slices with an SARD or CVE-ID that have valid CWE's associated with them.\n",
    "\n",
    "Additionally, I would like to include the group ID obtained from the 2A_Clustering_By_Asbtraction.ipynb file in the slice so I can measure the accuracy of the clustering model and classification predictions later on.\n",
    "\n",
    "<br />\n",
    "\n",
    "Option 1 requires a function that will match the SARD ID to the SARD ID in the *CWE_IDs.txt* file to retrieve the associated CWE-ID, the CVE ID to the *CVE_DF.csv* file to retrieve the associated CWE-ID (or 'NaN' if none), filter out any results that contain an obsolete, deprecated, or NaN ID, and output results to new files.\n",
    "\n",
    "**Pros:** Cleaner; It may make the subsequent code run faster since we won't have to do the additional filter steps of option 2; Would allow me to integrate the Group ID into the slice.\n",
    "\n",
    "**Cons:** Takes up more storage space; May be redundant since it's technically a subset of the original files; \n",
    "\n",
    "<br />\n",
    "\n",
    "Option 2 requires the same as option 1, except that function will need to be done at runtime, and return the results instead of outputting results to a file.\n",
    "\n",
    "**Pros:** Requires significantly less storage space than option 1.\n",
    "\n",
    "**Cons:** May contain duplicate code or would require the modification of the original file; Would make the slices-to-tokens conversion slower, which may not be too big of a problem if we only need to run it once. \n",
    "\n",
    "<br />\n",
    "\n",
    "It is hard to quantify whether removing the 6,655 slices to make the code run faster at the cost of taking up more space would be better than making the adjustments during runtime.  Also, I still need to evaluate how easy or hard it would be to integrate the Group ID into the slice or token if doing it at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slicesToTokens import *\n",
    "mycase_ID = tokenizeSlices(slicePath, tokenPath, numSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e5cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a6d020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a3796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86d1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SySe_VulnerabilityDetection] *",
   "language": "python",
   "name": "conda-env-SySe_VulnerabilityDetection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
