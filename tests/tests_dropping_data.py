#!/usr/bin/env python
# coding: utf-8

# Dropping with classes <100 samples from only vulnerable samples dataset.

import sys, os

VUL_PATH = os.environ.get('VUL_PATH')
sys.path.insert(1, VUL_PATH)


from utils import drop_classes_by_type, getDataset, drop_classes_by_count, get_class_indices_by_index, save_data_to_file


def test_downsampling_by_count(filepath, min_num):
    data = getDataset(filepath, getBalanced=False)
    print("Number of samples in our original vulnerable dataset: ", len(data[-1]))

    # Get ratios
    # return the indices of the unique array that can be used to reconstruct the array.
    classes, class_counts, class_indices = get_class_indices_by_index(data, index=-2)
    print(f'Classes: {classes}.\nClass Counts:{class_counts}.\n')
    classes, class_counts, class_indices = drop_classes_by_count(classes, class_counts, class_indices, min_num)
    print(f'Final Class: {classes}.\tClass Count:{class_counts}.')

    # Since the numpy functions to upsample didn't work, we'll do it the classic simple python way
    final_set = [[], [], [], [], [],[], []]

    for indices in class_indices:
        for i in indices:
            for group_index in range(len(data)):
                final_set[group_index].append(data[group_index][i])
    
    return final_set
# vector_path = os.path.join('data', 'DLvectors', 'SubSample_ALL_vulnerable')
# final_set = test_downsampling_by_count(vector_path, 2)


def test_downsampling_by_type(filepath, vType):
    data = getDataset(filepath, getBalanced=False)
    print("Number of samples in our original vulnerable dataset: ", len(data[-1]))
    print(f'\nFiltering out vulnerability syntax characteric types that are not of type {vType}...')

    classes, class_counts, class_indices = get_class_indices_by_index(data, index=4)
    classes, class_counts, class_indices = drop_classes_by_type(vType, classes, class_counts, class_indices)
    print(f'Final Classes: {classes}.\nClass Counts:{class_counts}.')
    # if we're also dropping by count, reset the original data to be able to replicate our process of extracting by x.
    final_set = [[], [], [], [], [],[], []]
    for indices in class_indices:
        for i in indices:
            for group_index in range(len(data)):
                final_set[group_index].append(data[group_index][i])
    
    # return final_set
    return final_set

# vector_path = os.path.join('data', 'DLvectors', 'ALL_vectors_granular_vulnerable_only') 
# final_set = test_downsampling_by_type(vector_path, 'API')
# print("Samples in new set: ", len(final_set[-1]))

# vector_path = os.path.join('data', 'DLvectors', 'API_vectors_vul')
# save_data_to_file(vector_path, 'ALL_vectors.pkl', final_set)





