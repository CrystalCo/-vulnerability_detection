import os

from pprint import pprint

from get_CWE_methods import get_ID_dict, get_vul_line_num_from_SARD


# Write a script that cross checks the vulnerability label and line 

#  3 parts:
    # Part 1: parse all SARD test cases that only contain 1 file & 1 vul line number
    # Part 2: parse the remaining by delim
    # Part 3: update labels
    # Part 4: cross check labels against our own


# Pull SARD IDs
# Using CWE_IDs.txt because SARD_IDs.txt contains duplicates
cwe_ids_file = os.path.join('data', 'CWE', 'CWE_IDs.txt')
SARD_IDs = get_ID_dict(cwe_ids_file)

# test data
# SARD_IDs = {
#     # case: 1 file 1 vul line number, but comment as vul line
#     '105801': {
#         'CWE-ID': '563',
#         'vulnerable_line_nums': []
#     },
#     # case: 2 comments before vul line
#     '104586': {
#         'CWE-ID': '476',
#         'vulnerable_line_nums': []
#     },
#     # case: contains >1 vul line number
#     '65292': {
#         'CWE-ID': '121',
#         'vulnerable_line_nums': []
#     }, 
#     # case: >1 vul filename
#     '78931': {
#         'CWE-ID': '127',
#         'vulnerable_line_nums': []
#     },
#     # case: printed to console as no file;; .cpp
#     '102802': {
#         'CWE-ID': '426',
#         'vulnerable_line_nums': []
#     }
# }


# scrapeout_path = os.path.join('..', 'data', '_temporaries', 'scrapeout.txt') # when running on terminal
scrapeout_path = os.path.join('data', '_temporaries', 'scrapeout.txt')
get_vul_line_num_from_SARD(SARD_IDs, scrapeout_path)
#pprint(SARD_IDs, width=300)


# Save SARD_IDs dict
scrapeout_path = os.path.join('data', '_SARD', 'sard_vulnerabilities.txt')
pprint(SARD_IDs, stream=open(scrapeout_path, 'w'), width=300)

