import os, sys

import numpy as np
from sklearn.model_selection import StratifiedKFold

VUL_PATH = os.environ.get('VUL_PATH')
sys.path.insert(1, VUL_PATH)

from utils.utils import GetDataXY, hot_encode_target


class CrossValidation():
    
    def __init__(self, classifier, k) -> None:
        self.model = classifier
        self.k = k
        self.metric_names = ['Mean Recall', 'Mean FPR', 'Mean FNR', 'Mean F1-score', 'Weighted Recall', 'Weighted FPR', 'Weighted FNR', 'Weighted F1-score']
        self.metrics = [[], [], [], [], [], [], [], []]

    def main(self):
        # Split data into training and test set
        ## Assumes our vectors are in 2D 
        print('\nSplitting train/test...')

        input_path = os.path.join(self.model.vectorsALLPath, 'ALL_vectors.pkl')
        X, y = GetDataXY(input_path, randomseed=self.model.randomSeed)
        X = np.array(X)
        y = np.array(y)
        skf = StratifiedKFold(n_splits=self.k, shuffle=True, random_state=self.model.randomSeed)

        for train_index, test_index in skf.split(X, y):
            # Reset checkpoints
            print('Resetting checkpoint and weights...')
            self.model.reset_checkpoint_and_weights(self.model.weightpath)

            # Stratified k-fold
            X_train, X_test = X[train_index], X[test_index]
            y_train, y_test = y[train_index], y[test_index]

            # hot encode labels
            categories = np.unique(y_train)
            self.model.labelEncoder = hot_encode_target(categories)[1]
            self.model.density_units = categories.shape[0]
            encoded_y_train = self.model.labelEncoder.transform(y_train)

            # Build DL model
            myKerasModel, checkpointCallback, latest_epoch = self.model.build_estimator()

            # fit with generator
            self.model.fit_estimator_with_generator(X_train, encoded_y_train, myKerasModel, checkpointCallback, latest_epoch)

            # Predict & score on our test set (does not have synthetic upsampling)
            encoded_y_test = self.model.labelEncoder.transform(y_test)
            metrics = self.model.predict_and_score(X_test, encoded_y_test)
            
            # Collect metrics
            metric_names = [ 'Mean Precision', 'Mean Recall', 'Mean FPR', 'Mean FNR', 'Mean F1-score', 'Weighted Precision', 'Weighted Recall', 'Weighted FPR', 'Weighted FNR', 'Weighted F1-score', 'Accuracy']
            for m, name in zip(metrics, metric_names):
                print('{}: {:.4f}'.format(name, m))

            self.metrics[0].append(metrics[1])
            self.metrics[1].append(metrics[2])
            self.metrics[2].append(metrics[3])
            self.metrics[3].append(metrics[4])
            self.metrics[4].append(metrics[6])
            self.metrics[5].append(metrics[7])
            self.metrics[6].append(metrics[8])
            self.metrics[7].append(metrics[9])

            print('\n\n\n\n\n\n')

        # Average out the scores
        print(f'Number of k-folds = {self.k}')
        for i in range(len(self.metrics)):
            avg = sum(self.metrics[i])/self.k
            print(f'Average score for {self.metric_names[i]}: {avg}')
        print('Length of metrics: %d ' % len(self.metrics[0]))

