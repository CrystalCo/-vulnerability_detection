import numpy as np

from utils.utils import GetData, SaveData
from utils.MLMethods import convert_nested_lists_to_numpy_arrays

def FlattenVectors(input_path, output_path, avg, vector_size):
    """ Flatten 3D vectors to 2D. """
    print('\nFlattening vectors to 2D')
    data = GetData(input_path)
    assert type(data[0][0][0]) == list or type(data[0][0][0]) == np.ndarray, f'Expected data[0][0][0] to be of type list or array. Instead it is type {type(data[0][0][0])}'
    assert len(data[0][0][0]) == 30, f'Expected data[0][0][0] to be of 30'
    print(f'Avg: {avg}\tVector length: {vector_size}')

    # Reshape from 3D to 2D
    input_shape_1 = avg * vector_size
    x = convert_nested_lists_to_numpy_arrays(data[0], avg, vector_size)
    x = np.reshape(x, (x.shape[0], input_shape_1))
    print(f'New vector size will be: {avg}x{vector_size}={str(input_shape_1)}')
    data[0] = x
    SaveData(output_path, data)

def getAvgLength(arr):
    """
        Return avg length of the inner arrays within an array,
        and the list of all the lengths in case you want to pick a value other than the avg.
    """
    totalSamples = len(arr)
    print("Total Samples: ", totalSamples)
    totalVectorLen = 0
    for i in range(totalSamples): 
        totalVectorLen += len(arr[i])
    return int(totalVectorLen/totalSamples)

def TrimData(input_path, output_path, maxLen, vector_dim):
        """
        Transforms the length of inner arrays within an array to `maxlen` (aka avg) size. 
        If shape of data is < maxlen, pads remainder with zeros.  If shape
        is > maxlen, truncates (maxlen/2) to the left and right of focus pointer.

        INPUTS:
            string paths that point to 
        OUTPUT:
            Reshaped data
        """
        data = truncateRows(input_path, maxLen, vector_dim)
        SaveData(output_path, data)

def truncateRows(dataSetpath, maxlen, vector_dim):
    """
        Truncates row length of data to match maxlen size, centering around 
        the focuspointer to ensure the data returned still contains the part 
        where the vulnerability lies in order to produce suitable data.
    """
    data = GetData(dataSetpath)
    X, focuspointers = data[0], data[2]
    new_X = []
    
    for x, focus in zip(X, focuspointers):
        if len(x) <  maxlen:
            remaining_length = maxlen - len(x)
            fill_0 = np.zeros((remaining_length, vector_dim))
            x = np.concatenate((x, fill_0))
            new_X.append(x)
        elif len(x) == maxlen:
            new_X.append(x)
        else:
            startpoint = int(focus - round(maxlen / 2.0))
            endpoint =  int(startpoint + maxlen)
            if startpoint < 0:
                startpoint = 0
                endpoint = maxlen
            if endpoint >= len(x):
                startpoint = -maxlen
                endpoint = None
            new_X.append(x[startpoint:endpoint])

    data[0] = new_X

    return data

def generator_of_data(data, labels, batchsize, maxlen, vector_dim):
    """
        Generator is used when there is too much data to fit into memory. 
        Generates batch_size number of the samples of the data at a time.
    """
    iter_num = int(len(data) / batchsize)
    i = 0
    
    while iter_num:
        batchdata = data[i:i + batchsize]
        # batchdata = process_sequences_shape(batchdata, maxlen, vector_dim)
        batched_labels = labels[i:i + batchsize]
        yield (batchdata, batched_labels)   # In keras fit(), returns tuple of (inputs, targets) b/c using a generator.  https://keras.io/api/models/model_training_apis/
        i = i + batchsize
        
        iter_num -= 1
        if iter_num == 0:
            iter_num = int(len(data) / batchsize)
            i = 0

def transformInput (onevectorsample, maxlen, vecdim):
    """Used in prediction."""
    nb_samples = np.zeros((1, maxlen, vecdim))
    sequence = onevectorsample

    i = 0
    m = 0
    for vectors in sequence:#500
        n = 0
        for values in vectors:#30
            nb_samples[i][m][n] += values
            n += 1
        m += 1
         
    print(np.shape(nb_samples))
    return nb_samples

