import pickle
import random
import time
import math
import os

import numpy as np
from sklearn.base import BaseEstimator
# from tensorflow.keras.metrics import TruePositives, TrueNegatives,FalsePositives, FalseNegatives
from keras.preprocessing import sequence
from keras import optimizers 
from keras.optimizers import SGD
from keras.models import Sequential
from keras.layers.core import Masking, Dense, Dropout, Activation
from keras.layers.recurrent import LSTM,GRU
from keras.layers.wrappers import Bidirectional
from keras.wrappers.scikit_learn import KerasClassifier

from SYSE_1_isVulnerable.preprocess_dl_Input_version5 import generator_of_data, process_sequences_shape
from SYSE_1_isVulnerable.DLPrediction import tranfromInput
from utils.utils import get_category

def create_bgru_model(maxlen, vector_dim=30, layers=2, dropout=0.1, optimizer='adam'):
    print('\nBuild BGRU Model')
    model = Sequential()
    model.add(Masking(mask_value=0.0, input_shape=(maxlen, vector_dim)))
    for i in range(1, layers):
        model.add(Bidirectional(GRU(units=256, activation='sigmoid', recurrent_activation='hard_sigmoid', return_sequences=True)))
        model.add(Dropout(dropout))
    model.add(Bidirectional(GRU(units=256, activation='sigmoid', recurrent_activation='hard_sigmoid')))
    model.add(Dropout(dropout))
    model.add(Dense(9, activation='sigmoid')) # Dense() outputs a function which takes a tensor as input and outputs a tensor. Might be our 'last' layer...
    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    model.summary() # WORKS! Up to here

    return model


class BGRUModel(BaseEstimator):
    def __init__(self, maxlen, units, epochs=10, layers=2, dropout=0.2, myoptimizer='adam', batch_size=32, vector_dim=30):
        self.bgru_model = None
        self.maxlen = maxlen
        self.units = units
        self.epochs = epochs
        self.vector_dim = vector_dim
        self.layers = layers
        self.dropout = dropout
        self.myoptimizer = myoptimizer
        self.batch_size = batch_size

    def fit(self, x, y=None): 
        print('Building model...')
        model = Sequential()
        model.add(Masking(mask_value=0.0, input_shape=(self.maxlen, self.vector_dim)))

        for i in range(1, self.layers):
            model.add(Bidirectional(GRU(units=256, activation='sigmoid', recurrent_activation='hard_sigmoid', return_sequences=True)))
            model.add(Dropout(self.dropout))
        
        model.add(Bidirectional(GRU(units=256, activation='sigmoid', recurrent_activation='hard_sigmoid')))
        model.add(Dropout(self.dropout))
        model.add(Dense(self.units, activation='sigmoid'))
        model.compile(loss='categorical_crossentropy', optimizer=self.myoptimizer, metrics=['accuracy'])
        model.summary()

        print('Fitting model...')

        train_generator = generator_of_data(x, y, self.batch_size, self.maxlen, self.vector_dim)   
        all_train_samples = len(x)
        steps_epoch = int(all_train_samples / self.batch_size)
        print(f'Length of dataset: {all_train_samples}.  Length of labels: {len(y)}')
        print("start")
        model.fit_generator(train_generator, steps_per_epoch=steps_epoch, epochs=self.epochs)

        self.bgru_model = model

        y = np.array(y)
        if len(y.shape) == 2 and y.shape[1] > 1:
            self.classes_ = np.arange(y.shape[1])
        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:
            self.classes_ = np.unique(y)
            y = np.searchsorted(self.classes_, y)
        else:
            raise ValueError('Invalid shape for y: ' + str(y.shape))
        self.n_classes_ = len(self.classes_)
    
        return self


    def predict(self, x):
        # kwargs = self.filter_sk_params(Sequential.predict, kwargs)
        myarr = process_sequences_shape(x, self.maxlen, self.vector_dim)#predict 25 programs in files
        # return self.bgru_model.predict(x=myarr, batch_size=1)
        return np.squeeze(self.bgru_model.predict(myarr, batch_size=1))


    def score(self, x, y):
        """
            Returns the mean accuracy on the given test data and labels.
            Args:
                x: array-like, shape `(n_samples, n_features)`
                    Test samples where `n_samples` is the number of samples
                    and `n_features` is the number of features.
                y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`
                    True labels for `x`.
                **kwargs: dictionary arguments
                    Legal arguments are the arguments of `Sequential.evaluate`.
            Returns:
                score: float
                    Mean accuracy of predictions on `x` wrt. `y`.
            Raises:
                ValueError: If the underlying model isn't configured to
                    compute accuracy. You should pass `metrics=["accuracy"]` to
                    the `.compile()` method of the model.
        """
        y = np.searchsorted(self.classes_, y)
        # kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)

        loss_name = self.bgru_model.loss
        if hasattr(loss_name, '__name__'):
            loss_name = loss_name.__name__
        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:
            from keras.utils.np_utils import to_categorical
            y = to_categorical(y)

        outputs = self.bgru_model.evaluate(x, y)
        if not isinstance(outputs, list):
            outputs = [outputs]
        for name, output in zip(self.bgru_model.metrics_names, outputs):
            if name in ['accuracy', 'acc']:
                return output
        raise ValueError('The model is not configured to compute accuracy. '
                        'You should pass `metrics=["accuracy"]` to '
                        'the `model.compile()` method.')
