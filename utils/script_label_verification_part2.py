import os
import ast
from pprint import pprint

from utils import get_SARD, get_sentences, get_vul_filename, levenshtein_ratio_and_distance


# Write a script that cross checks the vulnerability label and line 
# Phase 2: 
    # Compare our data samples to the vulnerable lines extracted from source


# Open SARD_IDs dict
sard_nodes_path = os.path.join('..', 'data', '_SARD', 'sard_vulnerabilities.txt')
# Read in txt as an object
# with open(sard_nodes_path, 'r') as f:
#     data = f.read()
# SARD_IDs = ast.literal_eval(data)    
# pprint(SARD_IDs)



# test data
SARD_IDs = {
    # case: mislabeled sample (missing atm)
    '1004': {
        'CWE-ID': '119', 
        'vulnerable_filenames': {
            'basic-00223-med.c': {
                'line_before_vul': [], 
                'vulnerable_lines': []
            }
        },
        'vulnerable_line_nums': [0]
    },
    # case: comment as vul line; omission of keyword is what makes it vul
    '100005': {
        'CWE-ID': '401', 
        'vulnerable_filenames': {
            'CWE401_Memory_Leak__new_array_twointsStruct_12.cpp': {
                'line_before_vul': ['{'], 
                'vulnerable_lines': ['/* POTENTIAL FLAW: No deallocation */']
            }
        }, 
        'vulnerable_line_nums': [53]
    },
    # case: easy target. Clear answer of 1 vulnerable line.
    '63582': {
        'CWE-ID': '121',
           'vulnerable_filenames': {
               'CWE121_Stack_Based_Buffer_Overflow__CWE193_wchar_t_alloca_memmove_64a.c':  {
                   'line_before_vul': [], 
                   'vulnerable_line_nums': [], 
                   'vulnerable_lines': []
                   },
                'CWE121_Stack_Based_Buffer_Overflow__CWE193_wchar_t_alloca_memmove_64b.c': {
                    'line_before_vul': ['/* POTENTIAL FLAW: data may not have enough space to hold source */', '/* POTENTIAL FLAW: data may not have enough space to hold source */'],
                    'vulnerable_line_nums': [37, 57],
                    'vulnerable_lines': ['memmove(data, source, (wcslen(source) + 1) * sizeof(wchar_t));', 'memmove(data, source, (wcslen(source) + 1) * sizeof(wchar_t));']
                }
            },
           'vulnerable_line_nums': [38]
        },
 
    # case: 2 comments before vul line, & comment in vul line
    # '104586': {
    #     'CWE-ID': '476',
    #     'vulnerable_filenames': {
    #         'CWE476_NULL_Pointer_Dereference__char_68a.c': {
    #             'line_before_vul': ['/* POTENTIAL FLAW: Set data to NULL */', '/* POTENTIAL FLAW: Set data to NULL */'], 
    #             'vulnerable_line_nums': [34, 62], 
    #             'vulnerable_lines': ['data = NULL;', 'data = NULL;']
    #             },
    #             'CWE476_NULL_Pointer_Dereference__char_68b.c': {
    #                 'line_before_vul': ['/* POTENTIAL FLAW: Attempt to use data, which may be NULL *//* printLine() checks for NULL, so we cannot use it here */', '/* POTENTIAL FLAW: Attempt to use data, which may be NULL *//* POTENTIAL FLAW: Attempt to use data, which may be NULL */'],
    #                 'vulnerable_line_nums': [32, 44],
    #                 'vulnerable_lines': ['printHexCharLine(data[0]);', '/* printLine() checks for NULL, so we cannot use it here */']
    #             }
    #         },
    #         'vulnerable_line_nums': [33]
    #     },
    # case: contains >1 vul line number
    '65292': {
        'CWE-ID': '121',
        'vulnerable_filenames': {
            'CWE121_Stack_Based_Buffer_Overflow__CWE805_wchar_t_declare_loop_33.cpp': {
                'line_before_vul': ['/* POTENTIAL FLAW: Possible buffer overflow if the size of data is less than the length of source */', '/* POTENTIAL FLAW: Possible buffer overflow if the size of data is less than the length of source */'],
                'vulnerable_line_nums': [43, 75],
                'vulnerable_lines': ['for (i = 0; i < 100; i++)', 'for (i = 0; i < 100; i++)']
            }
        },
        'vulnerable_line_nums': [34, 46]
    },
    # non-vulnerable sample (missing atm)
    '1002': {
        'CWE-ID': '119', 
        'vulnerable_filenames': {
            'basic-00222-ok.c': {
                'line_before_vul': [], 
                'vulnerable_lines': []
            }
        }, 
        'vulnerable_line_nums': [0]
    },
}



# Next step, once we have all the vul line numbers per SARD,
# walk through the parsed, raw files,
nonvulnerable_filepath = os.path.join('data', 'slicesByLabel', 'nonvulnerable_slices.txt')
vulnerable_filepath = os.path.join('data', 'slicesByLabel', 'vulnerable_slices.txt')
splitter = '------------------------------\n'

# slicepath = os.path.join('data', 'slicesSource')
# for filename in os.listdir(slicepath):
#     if(filename.endswith('.txt') is False):
#         continue
#     print('Slice File To be Processed: ', filename)
#     f1 = open(os.path.join(slicepath, filename), 'r')

# TEST. Uncomment above and tab the following lines after done testing
filename = os.path.join('data', 'slicesSource', 'Array usage.txt')
f1 = open(filename, 'r')
slices = f1.read().split(splitter)# split each slice 
f1.close()

# Remove whitespace buffers in first and last lines of slice
if slices[0] == '':
    del slices[0]
if slices[-1] == '' or slices[-1] == '\n' or slices[-1] == '\r\n':
    del slices[-1]

# Iterate each data sample
for vul_slice in slices:
    sentences = get_sentences(vul_slice)
    # get header, which contains the filename and SARD number
    sard = get_SARD(sentences[0])   # returns a string
    vul_filename = get_vul_filename(sentences[0])

    # get vulnerable label (for stats)
    label_from_slice = sentences[-1].strip()
    matching_label_count = 0 
    nonmatching_label_count = 0 

    # match the SARD & filename with the ones in our dictionary
    if sard not in SARD_IDs.keys():
        # print('SARD %s slice not in SARD dictionary.' % sard)
        continue

    if vul_filename not in SARD_IDs[sard]['vulnerable_filenames'].keys():
        print('SARD %s missing filename %s found in slice. SARD node filenames: %s.' % (sard, vul_filename, SARD_IDs['vulnerable_filenames'].keys()))
        continue


    vulnerable_obj = None if not SARD_IDs[sard]['vulnerable_filenames'][vul_filename] else SARD_IDs[sard]['vulnerable_filenames'][vul_filename]

    # Skip CVE slices
    if vulnerable_obj == None:
        continue


    isVulnerable = False

    # Check if this slice is vulnerable - validate vulnerable syntax in there
    for vulnerable_line in vulnerable_obj['vulnerable_lines']:
        # METHOD: SPECIAL CASES
        
        # METHOD: EQUIVALENCE CHECK
        # METHOD: SIMILARITY METRIC
        for sentence in sentences:
            #  strip all spaces in both strings to check for equality
            vul_line_stripped = vulnerable_line.replace(' ', '')
            sentence_stripped = sentence.replace(' ', '')

            if vul_line_stripped == sentence_stripped:
                isVulnerable = True
                
                # Update stats
                if label_from_slice == '1':
                    matching_label_count += 1
                else:
                    nonmatching_label_count += 1
                
                # Ensure slice is correctly labeled
                sentences[-1] = '1'
                break
            
            # In case the vulnerable line is in the code but doesn't exactly match the stripped version, compute the similarity distance
            similarity_distance = levenshtein_ratio_and_distance(vul_line_stripped, sentence_stripped, True)

            # TODO: Test a sample batch if 0.95 is a good confidence threshold
            # Check using slices that have the vulnerable line vs their fixed line
            if similarity_distance > 0.95:
                isVulnerable = True

                if label_from_slice == '1':
                    matching_label_count += 1
                else:
                    nonmatching_label_count += 1
                
                # Ensure slice is correctly labeled
                sentences[-1] = '1'
                break
        if isVulnerable:
            break

    # piece sentences back together as a slice
    sentences.append(splitter)
    new_slice = '\n'.join(sentences)

    if isVulnerable:
        # Put the slices that contain vulnerabilities in one file
        with open(vulnerable_filepath, 'a') as f:
            f.write(new_slice)
    else:
        # place other slices in separate file
        with open(nonvulnerable_filepath, 'a') as f:
            f.write(new_slice)



# Custom function check depending on special case

def special_case_no_deallocation(sentences):
    # if a 'new' exists, then a 'delete' should exist
    # prone to error if delete called on a variable that wasn't set to new
    sentences = set(sentences)

    if 'new' in sentences and 'delete' not in sentences:
        return True
    elif 'malloc' in sentences and 'free' not in sentences:
        return True
    else:
        return False

def special_case_empty_statement(prev_line):
    # different methods that could lead to what the actual flaw is
    if prev_line in special_cases_dict.keys():
        return special_cases_dict[prev_line]




special_cases_dict = {
    '/* no deallocation */': special_case_no_deallocation, 
    '/* POTENTIAL FLAW: No deallocation */': special_case_no_deallocation, 
    '/* POTENTIAL FLAW: No deallocation of memory *//* no deallocation */': special_case_no_deallocation,
    '/* printLine() checks for NULL, so we cannot use it here */': [], 
    '/* printWLine() checks for NULL, so we cannot use it here */': [], 
    '/* do nothing */': [], 
    '/* Logged in XXXXX Smith using password ABCD1234 */': [], 
    '/* FLAW: No attempt to close the file */': [], 
    '/* POTENTIAL FLAW: set the hostname to data obtained from a potentially external source */': [], 
    '/* FLAW: Release password from the stack without first clearing the buffer */': [], 
    '/* Use the derived key to encrypt something */': [], 
    '/* FLAW: Missing required step (CryptEncrypt) does not encrypt the payload */': [], 
    '/* FLAW: Do not check to see if wcstombs() failed */': [],
    '; /* empty statement needed for some flow variants */': special_case_empty_statement, 
    '/* POTENTIAL FLAW: Don\'t initialize data */': [],
    '/* FLAW: Do not initialize data */': [], 
    '/* POTENTIAL FLAW: Do not initialize or use data */': [],
}

